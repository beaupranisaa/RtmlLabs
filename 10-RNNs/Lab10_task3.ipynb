{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-springer",
   "metadata": {},
   "source": [
    "### TASK3: Do a bit of research on similar problems such as named entity recognition, find a dataset, train a model, and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-monte",
   "metadata": {},
   "source": [
    "The chosen data is taken from https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus?select=ner_dataset.csv\n",
    "    \n",
    "And the data set is for name entity recodnition, the two columns selected are 'Word' and 'POS' <br>\n",
    "The model was trained on SGD optimizer with lr of 0.01 and a momentum of 0.9 and a loss function of NNLLoss()\n",
    "And the results are as follows:\n",
    "\n",
    "Top-1 Accuracy: 0.917979162196314 Top-2 Accuracy: 0.9770784159454498 <br>\n",
    "CPU times: user 55min 8s, sys: 1min, total: 56min 8s <br>\n",
    "Wall time: 10min 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "armed-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "several-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "from chosen_gpu import get_freer_gpu\n",
    "device = torch.device(get_freer_gpu()) \n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-contents",
   "metadata": {},
   "source": [
    "### 1. Load data\n",
    "\n",
    "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus?select=ner_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "married-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "df = pd.read_csv('ner_dataset.csv', encoding= 'unicode_escape') \n",
    "df = df.fillna(method=\"ffill\")\n",
    "df = df.drop(['Tag'], axis =1)\n",
    "df = df.drop(['Sentence #'], axis =1)\n",
    "# words = df['Word']\n",
    "# tags = df['POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-survivor",
   "metadata": {},
   "source": [
    "#### 1.1 Build the cat_words dictionary, a list of tags per word and a list of all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bronze-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_words = {}\n",
    "all_tags = []\n",
    "all_words = []\n",
    "tags = list(set(df[\"POS\"].values))\n",
    "\n",
    "for i in tags:\n",
    "    cat_words[i] = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    cat_words[df['POS'].iloc[i]].append(df['Word'].iloc[i])\n",
    "    all_tags.append(df['POS'].iloc[i])\n",
    "    all_words.append(df['Word'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "periodic-scratch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP:131426\n",
      "``:3728\n",
      "VBN:32328\n",
      "PDT:147\n",
      "RB:20252\n",
      "WDT:3698\n",
      "MD:6973\n",
      "CC:23716\n",
      "RBS:296\n",
      "PRP:13318\n",
      "EX:663\n",
      "VBG:19125\n",
      "NN:145807\n",
      "RBR:1055\n",
      "UH:24\n",
      "JJR:2967\n",
      "VBD:39379\n",
      ".:47831\n",
      "TO:23061\n",
      "::795\n",
      "NNPS:2521\n",
      "WP:2542\n",
      ",:32757\n",
      "JJS:3034\n",
      "WRB:2184\n",
      "IN:120996\n",
      "VBP:16158\n",
      "WP$:99\n",
      "DT:98454\n",
      ";:214\n",
      "VBZ:24960\n",
      "FW:1\n",
      "CD:24695\n",
      "LRB:678\n",
      "RRB:679\n",
      "PRP$:8655\n",
      "POS:11257\n",
      "JJ:78412\n",
      "$:1149\n",
      "VB:24211\n",
      "RP:2490\n",
      "NNS:75840\n",
      "1048575\n",
      "1048575\n"
     ]
    }
   ],
   "source": [
    "for i in tags:\n",
    "    print(f'{i}:{len(cat_words[i])}')\n",
    "    \n",
    "print(len(all_words))\n",
    "print(len(all_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-paste",
   "metadata": {},
   "source": [
    "#### All words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rocky-station",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!' '\"' '#' ... '\\x96' '\\x97' 'Â°C']\n",
      "35178\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(df['Word']))\n",
    "print(len(np.unique(df['Word'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-addition",
   "metadata": {},
   "source": [
    "#### All tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "endless-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$' ',' '.' ':' ';' 'CC' 'CD' 'DT' 'EX' 'FW' 'IN' 'JJ' 'JJR' 'JJS' 'LRB'\n",
      " 'MD' 'NN' 'NNP' 'NNPS' 'NNS' 'PDT' 'POS' 'PRP' 'PRP$' 'RB' 'RBR' 'RBS'\n",
      " 'RP' 'RRB' 'TO' 'UH' 'VB' 'VBD' 'VBG' 'VBN' 'VBP' 'VBZ' 'WDT' 'WP' 'WP$'\n",
      " 'WRB' '``']\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(tags))\n",
    "print(len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-isaac",
   "metadata": {},
   "source": [
    "### 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "duplicate-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_words, all_tags, test_size = 0.2, random_state = 123) #, stratify = pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stainless-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the training data:  838860\n",
      "The number of observations in the test data:  209715\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of observations in the training data: \", len(X_train))\n",
    "print(\"The number of observations in the test data: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-reviewer",
   "metadata": {},
   "source": [
    "### 3. Encode words and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "banned-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create representation of the name\n",
    "def word_rep(word):\n",
    "    rep = torch.zeros(len(word), 1, n_letters) #Create a zeros tensor\n",
    "    #iterate through all the characters in the name\n",
    "    for index, letter in enumerate(word):\n",
    "        pos = all_letters.find(letter)\n",
    "        rep[index][0][pos] = 1 #Assign a value for each pos value\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "atmospheric-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create vec representation of the language\n",
    "def tag_rep(tag):\n",
    "    return torch.tensor([tags.index(tag)], dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-controversy",
   "metadata": {},
   "source": [
    "#### Example of word and tag representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "novel-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([4, 1, 57])\n",
      "tensor([28])\n"
     ]
    }
   ],
   "source": [
    "#example of name representation\n",
    "beau = word_rep(\"beau\")\n",
    "print(beau)\n",
    "print(beau.shape)\n",
    "\n",
    "tag = tag_rep(\"DT\")\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-killer",
   "metadata": {},
   "source": [
    "### 4. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "employed-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple rnn network \n",
    "import torch.nn as nn\n",
    "class RNN_net(nn.Module):\n",
    "    #Create a constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_net, self).__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        self.rnn_cell = nn.RNN(input_size, hidden_size)\n",
    "        self.h20 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    #create a forward pass function\n",
    "    def forward(self, input_, hidden = None, batch_size = 1):\n",
    "        out, hidden = self.rnn_cell(input_, hidden)\n",
    "        output = self.h20(hidden.view(-1, self.hidden_size))\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size = 1):\n",
    "        #function to init the hidden layers\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-albania",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "vanilla-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run interference\n",
    "def infer(net, name, device = \"cpu\"):\n",
    "    name_ohe = word_rep(name).to(device)\n",
    "\n",
    "    #get the output\n",
    "    output, hidden = net(name_ohe)\n",
    "\n",
    "    if type(hidden) is tuple: #for lSTM\n",
    "        hidden = hidden[0]\n",
    "    index = torch.argmax(hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "quantitative-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tags present:  42\n"
     ]
    }
   ],
   "source": [
    "#create hidden layers\n",
    "n_hidden = 128 #hidden layers count\n",
    "\n",
    "#number of tags\n",
    "n_tags= len(cat_words.keys())\n",
    "print(\"Total number of tags present: \", n_tags)\n",
    "\n",
    "#initialize the network\n",
    "net = RNN_net(input_size=n_letters, hidden_size=n_hidden, output_size=n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "verbal-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7101, -3.7837, -3.7638, -3.6738, -3.7322, -3.8714, -3.8046, -3.7407,\n",
       "         -3.8662, -3.7178, -3.7269, -3.6650, -3.7664, -3.7766, -3.7517, -3.7422,\n",
       "         -3.8214, -3.6814, -3.7943, -3.7446, -3.6949, -3.7062, -3.8419, -3.6371,\n",
       "         -3.7452, -3.6865, -3.6187, -3.6388, -3.7371, -3.8577, -3.7310, -3.6975,\n",
       "         -3.7140, -3.7254, -3.7686, -3.6913, -3.7332, -3.7029, -3.7157, -3.7756,\n",
       "         -3.6985, -3.8031]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for inference\n",
    "net = net.to(device)\n",
    "infer(net, \"kumar\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "pediatric-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7256, -3.7546, -3.7892, -3.6754, -3.6894, -3.8181, -3.7581, -3.7202,\n",
       "         -3.8300, -3.6722, -3.6850, -3.7424, -3.7674, -3.7925, -3.7973, -3.7730,\n",
       "         -3.7930, -3.6093, -3.8378, -3.7816, -3.6645, -3.7387, -3.8039, -3.6786,\n",
       "         -3.7691, -3.7115, -3.6383, -3.6441, -3.7763, -3.8337, -3.6468, -3.6908,\n",
       "         -3.6748, -3.7310, -3.8185, -3.6466, -3.7817, -3.7214, -3.7556, -3.8219,\n",
       "         -3.7053, -3.7970]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = word_rep('A')\n",
    "\n",
    "# put stuff on GPU\n",
    "input = input.to(device)\n",
    "hidden = torch.zeros((1,1, n_hidden)).to(device)\n",
    "\n",
    "output, next_hidden = net(input, hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "unusual-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7256, -3.7546, -3.7892, -3.6754, -3.6894, -3.8181, -3.7581, -3.7202,\n",
      "         -3.8300, -3.6722, -3.6850, -3.7424, -3.7674, -3.7925, -3.7973, -3.7730,\n",
      "         -3.7930, -3.6093, -3.8378, -3.7816, -3.6645, -3.7387, -3.8039, -3.6786,\n",
      "         -3.7691, -3.7115, -3.6383, -3.6441, -3.7763, -3.8337, -3.6468, -3.6908,\n",
      "         -3.6748, -3.7310, -3.8185, -3.6466, -3.7817, -3.7214, -3.7556, -3.8219,\n",
      "         -3.7053, -3.7970]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.7417, -3.7391, -3.7758, -3.6708, -3.6568, -3.7514, -3.8263, -3.7489,\n",
      "         -3.8795, -3.7125, -3.7390, -3.6674, -3.7828, -3.6888, -3.7516, -3.7476,\n",
      "         -3.8114, -3.5825, -3.7930, -3.7743, -3.6775, -3.7027, -3.7602, -3.7700,\n",
      "         -3.7316, -3.7220, -3.6404, -3.6993, -3.7385, -3.8266, -3.7213, -3.6682,\n",
      "         -3.7103, -3.7382, -3.7721, -3.6905, -3.8237, -3.7307, -3.6579, -3.8277,\n",
      "         -3.7440, -3.8662]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.6819, -3.7936, -3.7914, -3.6230, -3.7738, -3.7930, -3.8007, -3.7838,\n",
      "         -3.8044, -3.6951, -3.6763, -3.6510, -3.8428, -3.7512, -3.7488, -3.7570,\n",
      "         -3.7820, -3.6198, -3.7406, -3.7853, -3.6886, -3.7357, -3.8209, -3.6684,\n",
      "         -3.7108, -3.6488, -3.6490, -3.6905, -3.6998, -3.8608, -3.6922, -3.7284,\n",
      "         -3.6912, -3.7314, -3.7218, -3.7582, -3.7952, -3.7664, -3.6890, -3.8323,\n",
      "         -3.7402, -3.8481]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.7646, -3.7730, -3.7986, -3.6864, -3.7179, -3.8664, -3.7660, -3.7817,\n",
      "         -3.7883, -3.7097, -3.6801, -3.6703, -3.7928, -3.7749, -3.8181, -3.7810,\n",
      "         -3.8945, -3.6499, -3.7539, -3.7415, -3.6094, -3.7148, -3.7963, -3.6513,\n",
      "         -3.7288, -3.6601, -3.6171, -3.5824, -3.7841, -3.8322, -3.6344, -3.7188,\n",
      "         -3.6641, -3.6999, -3.7786, -3.6543, -3.8588, -3.8002, -3.7411, -3.8097,\n",
      "         -3.7553, -3.7927]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.7373, -3.7632, -3.7761, -3.6725, -3.7190, -3.8795, -3.7819, -3.7607,\n",
      "         -3.8387, -3.6998, -3.7306, -3.6843, -3.7790, -3.7892, -3.7592, -3.7402,\n",
      "         -3.8419, -3.6711, -3.8186, -3.7352, -3.6813, -3.7269, -3.7961, -3.6405,\n",
      "         -3.7422, -3.6719, -3.6296, -3.5955, -3.7515, -3.8774, -3.7063, -3.7124,\n",
      "         -3.6973, -3.7212, -3.7552, -3.6494, -3.8172, -3.6979, -3.7412, -3.7648,\n",
      "         -3.7166, -3.7948]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.7370, -3.8110, -3.7710, -3.6596, -3.7193, -3.8272, -3.7731, -3.8884,\n",
      "         -3.7653, -3.7264, -3.7765, -3.6107, -3.7879, -3.7061, -3.7567, -3.7502,\n",
      "         -3.8029, -3.6482, -3.8015, -3.7090, -3.6209, -3.7321, -3.7687, -3.5916,\n",
      "         -3.6854, -3.6805, -3.7042, -3.6738, -3.7563, -3.9156, -3.6669, -3.7009,\n",
      "         -3.6472, -3.7012, -3.7883, -3.7199, -3.8495, -3.7716, -3.7169, -3.7825,\n",
      "         -3.7335, -3.8522]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = word_rep('Albert')\n",
    "hidden = torch.zeros((1,1, n_hidden))\n",
    "\n",
    "# put stuff on GPU\n",
    "input = input.to(device)\n",
    "hidden = hidden.to(device)\n",
    "\n",
    "next_hidden = hidden\n",
    "for i in range(input.shape[0]):\n",
    "    output, next_hidden = net(input[i].reshape(1,1,-1), next_hidden)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-monaco",
   "metadata": {},
   "source": [
    "### 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cardiovascular-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for l in all_tags: \n",
    "    count[l] = 0\n",
    "for k,v in cat_words.items():\n",
    "    count[k] += len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "molecular-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NNS': 75840, 'IN': 120996, 'VBP': 16158, 'VBN': 32328, 'NNP': 131426, 'TO': 23061, 'VB': 24211, 'DT': 98454, 'NN': 145807, 'CC': 23716, 'JJ': 78412, '.': 47831, 'VBD': 39379, 'WP': 2542, '``': 3728, 'CD': 24695, 'PRP': 13318, 'VBZ': 24960, 'POS': 11257, 'VBG': 19125, 'RB': 20252, ',': 32757, 'WRB': 2184, 'PRP$': 8655, 'MD': 6973, 'WDT': 3698, 'JJR': 2967, ':': 795, 'JJS': 3034, 'WP$': 99, 'RP': 2490, 'PDT': 147, 'NNPS': 2521, 'EX': 663, 'RBS': 296, 'LRB': 678, 'RRB': 679, '$': 1149, 'RBR': 1055, ';': 214, 'UH': 24, 'FW': 1}\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sudden-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAENCAYAAADzFzkJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xm8HFWd9/HP18TIZgxLWB4CBMeMCowKRoy4jJoRAqIBgRnQmUTMGGGCAuKMIDODA6I4+IiyiBNNJChDRBCIEIx5WFQcloQtYc+VNYAQTECUEQz+nj/OaVLpVFfX7U7uvbn5vl+vft3uU6dOneqqrl/VqV/3VURgZmZWxyv6uwNmZrb+cNAwM7PaHDTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zMahva3x1Y27baaqsYPXp0f3fDzGy9cssttzwdESPb1Rt0QWP06NEsXLiwv7thZrZekfRwnXoenjIzs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2hw0zMysNgcNMzOrzUHDzMxqG3Rf7jO4bOa+peUHfOKqPu6JmQ02vtIwM7PaHDTMzKw2Bw0zM6vNQcPMzGprGzQkzZT0lKQ7S6Z9TlJI2iq/lqQzJfVIWiRpj0LdyZKW5MfkQvlbJS3O85wpSbl8C0nzc/35kjZfO6tsZmadqnOlcR4woblQ0g7AB4BHCsX7AmPyYypwbq67BXAS8HZgT+CkQhA4N9dtzNdY1vHA1RExBrg6vzYzs37UNmhExC+A5SWTzgD+BYhC2UTg/EhuBEZI2g7YB5gfEcsjYgUwH5iQpw2PiBsiIoDzgQMKbc3Kz2cVys3MrJ90dE9D0oeBxyLijqZJ2wOPFl4vzWVV5UtLygG2iYgnAPLfrTvpq5mZrT29/nKfpE2AE4G9yyaXlEUH5b3t01TSEBc77rhjb2c3M7OaOrnS+AtgZ+AOSQ8Bo4BbJW1LulLYoVB3FPB4m/JRJeUAT+bhK/Lfp1p1KCKmR8TYiBg7cmTbf3FrZmYd6nXQiIjFEbF1RIyOiNGkA/8eEfEbYA4wKWdRjQOezUNL84C9JW2eb4DvDczL056TNC5nTU0CLs+LmgM0sqwmF8rNzKyf1Em5vRC4AXi9pKWSplRUnws8APQA3wH+CSAilgOnAAvy4+RcBnAk8N08z6+Bxg8knQZ8QNISUpbWab1bNTMzW9va3tOIiMPaTB9deB7AtBb1ZgIzS8oXAruVlP8WGN+uf2Zm1nf8jXAzM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2nr921PW3pKzJ5aWjznKX2o3s/WbrzTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2hw0zMysNgcNMzOrzUHDzMxqc9AwM7Pa2gYNSTMlPSXpzkLZ6ZLulbRI0qWSRhSmnSCpR9J9kvYplE/IZT2Sji+U7yzpJklLJP1Q0rBc/qr8uidPH722VtrMzDpT50rjPGBCU9l8YLeIeBNwP3ACgKRdgEOBXfM835I0RNIQ4BxgX2AX4LBcF+CrwBkRMQZYAUzJ5VOAFRHxOuCMXM/MzPpR259Gj4hfNJ/lR8TPCi9vBA7OzycCsyPiBeBBST3AnnlaT0Q8ACBpNjBR0j3A+4GP5jqzgC8C5+a2vpjLLwbOlqSIiF6sX6ll3/52afnII47otmkzs0FtbdzT+ARwVX6+PfBoYdrSXNaqfEvgmYhY2VS+Wlt5+rO5/hokTZW0UNLCZcuWdb1CZmZWrqugIelEYCVwQaOopFp0UF7V1pqFEdMjYmxEjB05cmR1p83MrGMd/+c+SZOB/YHxhSGjpcAOhWqjgMfz87Lyp4ERkobmq4li/UZbSyUNBV4DLO+0v2Zm1r2OrjQkTQA+D3w4Ip4vTJoDHJozn3YGxgA3AwuAMTlTahjpZvmcHGyuZdU9kcnA5YW2JufnBwPXrI37GWZm1rm2VxqSLgTeC2wlaSlwEilb6lXAfEkAN0bEERFxl6SLgLtJw1bTIuKl3M5RwDxgCDAzIu7Ki/g8MFvSl4DbgBm5fAbw/XwzfTkp0JiZWT+qkz11WEnxjJKyRv1TgVNLyucCc0vKH2BVhlWx/I/AIe36Z2ZmfcffCDczs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2hw0zMysNgcNMzOrzUHDzMxqc9AwM7PaHDTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2hw0zMysNgcNMzOrrW3QkDRT0lOS7iyUbSFpvqQl+e/muVySzpTUI2mRpD0K80zO9ZdImlwof6ukxXmeMyWpahlmZtZ/6lxpnAdMaCo7Hrg6IsYAV+fXAPsCY/JjKnAupAAAnAS8HdgTOKkQBM7NdRvzTWizDDMz6ydtg0ZE/AJY3lQ8EZiVn88CDiiUnx/JjcAISdsB+wDzI2J5RKwA5gMT8rThEXFDRARwflNbZcswM7N+0uk9jW0i4gmA/HfrXL498Gih3tJcVlW+tKS8ahlmZtZP1vaNcJWURQflvVuoNFXSQkkLly1b1tvZzcyspk6DxpN5aIn896lcvhTYoVBvFPB4m/JRJeVVy1hDREyPiLERMXbkyJEdrpKZmbUztMP55gCTgdPy38sL5UdJmk266f1sRDwhaR7w5cLN772BEyJiuaTnJI0DbgImAWe1WcYGb96M/UrL95kyt497YmYbmrZBQ9KFwHuBrSQtJWVBnQZcJGkK8AhwSK4+F9gP6AGeBw4HyMHhFGBBrndyRDRurh9JytDaGLgqP6hYhpmZ9ZO2QSMiDmsxaXxJ3QCmtWhnJjCzpHwhsFtJ+W/LlmFmZv3H3wg3M7PaHDTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zManPQMDOz2hw0zMysNgcNMzOrzUHDzMxqc9AwM7PaHDTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zMausqaEg6VtJdku6UdKGkjSTtLOkmSUsk/VDSsFz3Vfl1T54+utDOCbn8Pkn7FMon5LIeScd301czM+tex0FD0vbAZ4CxEbEbMAQ4FPgqcEZEjAFWAFPyLFOAFRHxOuCMXA9Ju+T5dgUmAN+SNETSEOAcYF9gF+CwXNfMzPpJt8NTQ4GNJQ0FNgGeAN4PXJynzwIOyM8n5tfk6eMlKZfPjogXIuJBoAfYMz96IuKBiHgRmJ3rmplZP+k4aETEY8DXgEdIweJZ4BbgmYhYmastBbbPz7cHHs3zrsz1tyyWN83TqnwNkqZKWihp4bJlyzpdJTMza6Ob4anNSWf+OwP/B9iUNJTULBqztJjW2/I1CyOmR8TYiBg7cuTIdl03M7MODe1i3r8BHoyIZQCSfgzsBYyQNDRfTYwCHs/1lwI7AEvzcNZrgOWF8obiPK3KbR2Zcf7eLadNmfSzPuyJmQ1E3dzTeAQYJ2mTfG9iPHA3cC1wcK4zGbg8P5+TX5OnXxMRkcsPzdlVOwNjgJuBBcCYnI01jHSzfE4X/TUzsy51fKURETdJuhi4FVgJ3AZMB64EZkv6Ui6bkWeZAXxfUg/pCuPQ3M5dki4iBZyVwLSIeAlA0lHAPFJm1syIuKvT/pqZWfe6GZ4iIk4CTmoqfoCU+dRc94/AIS3aORU4taR8LjC3mz6amdna01XQGKiWnfuD0vKRR/59H/fEzGxw8c+ImJlZbQ4aZmZWm4OGmZnV5qBhZma1OWiYmVltDhpmZlabg4aZmdXmoGFmZrU5aJiZWW0OGmZmVpuDhpmZ1eagYWZmtTlomJlZbQ4aZmZWm4OGmZnV5qBhZma1OWiYmVltDhpmZlZbV0FD0ghJF0u6V9I9kt4haQtJ8yUtyX83z3Ul6UxJPZIWSdqj0M7kXH+JpMmF8rdKWpznOVOSuumvmZl1p9srjW8CP42INwBvBu4BjgeujogxwNX5NcC+wJj8mAqcCyBpC+Ak4O3AnsBJjUCT60wtzDehy/6amVkXOg4akoYD7wFmAETEixHxDDARmJWrzQIOyM8nAudHciMwQtJ2wD7A/IhYHhErgPnAhDxteETcEBEBnF9oy8zM+kE3VxqvBZYB35N0m6TvStoU2CYingDIf7fO9bcHHi3MvzSXVZUvLSlfg6SpkhZKWrhs2bIuVsnMzKp0EzSGAnsA50bE7sAfWDUUVabsfkR0UL5mYcT0iBgbEWNHjhxZ3WszM+tYN0FjKbA0Im7Kry8mBZEn89AS+e9Thfo7FOYfBTzepnxUSbmZmfWTjoNGRPwGeFTS63PReOBuYA7QyICaDFyen88BJuUsqnHAs3n4ah6wt6TN8w3wvYF5edpzksblrKlJhbbMzKwfDO1y/k8DF0gaBjwAHE4KRBdJmgI8AhyS684F9gN6gOdzXSJiuaRTgAW53skRsTw/PxI4D9gYuCo/zMysn3QVNCLidmBsyaTxJXUDmNainZnAzJLyhcBu3fTRzMzWHn8j3MzManPQMDOz2hw0zMysNgcNMzOrzUHDzMxqc9AwM7PaHDTMzKw2Bw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq63bX7m1DczZF+zTctpRH5vXhz0xs/7gKw0zM6vNQcPMzGpz0DAzs9ocNMzMrDYHDTMzq81Bw8zMaus6aEgaIuk2SVfk1ztLuknSEkk/lDQsl78qv+7J00cX2jghl98naZ9C+YRc1iPp+G77amZm3VkbVxpHA/cUXn8VOCMixgArgCm5fAqwIiJeB5yR6yFpF+BQYFdgAvCtHIiGAOcA+wK7AIflumZm1k+6ChqSRgEfBL6bXwt4P3BxrjILOCA/n5hfk6ePz/UnArMj4oWIeBDoAfbMj56IeCAiXgRm57pmZtZPur3S+AbwL8Cf8+stgWciYmV+vRTYPj/fHngUIE9/Ntd/ubxpnlblZmbWTzoOGpL2B56KiFuKxSVVo8203paX9WWqpIWSFi5btqyi12Zm1o1ufnvqncCHJe0HbAQMJ115jJA0NF9NjAIez/WXAjsASyUNBV4DLC+UNxTnaVW+moiYDkwHGDt2bGlgsb7x1dmtf5vq84f6t6nM1ncdX2lExAkRMSoiRpNuZF8TER8DrgUOztUmA5fn53Pya/L0ayIicvmhObtqZ2AMcDOwABiTs7GG5WXM6bS/ZmbWvXXxK7efB2ZL+hJwGzAjl88Avi+ph3SFcShARNwl6SLgbmAlMC0iXgKQdBQwDxgCzIyIu9ZBf83MrKa1EjQi4jrguvz8AVLmU3OdPwKHtJj/VODUkvK5wNy10UczM+uevxFuZma1OWiYmVltDhpmZlabg4aZmdXmoGFmZrWti5RbM2th/4svaDntioM/1oc9MeuMg0YHHjtnWmn59tPO6eOemJn1LQ9PmZlZbQ4aZmZWm4OGmZnV5qBhZma1OWiYmVltDhpmZlabg4aZmdXmoGFmZrU5aJiZWW3+RritV/a9fHLLaVdNnNV2/v0u/XLLaXMP/EJHfTLbkDhoDEC//M7+peXv/uQVfdwTM7PVOWhsYC48b5+W0w77+Lw+7ImZrY8cNPrBrd/+UGn5Hkf8pI97YmbWOx3fCJe0g6RrJd0j6S5JR+fyLSTNl7Qk/908l0vSmZJ6JC2StEehrcm5/hJJkwvlb5W0OM9zpiR1s7JmZtadbrKnVgLHRcQbgXHANEm7AMcDV0fEGODq/BpgX2BMfkwFzoUUZICTgLcDewInNQJNrjO1MN+ELvprZmZd6jhoRMQTEXFrfv4ccA+wPTARaKSxzAIOyM8nAudHciMwQtJ2wD7A/IhYHhErgPnAhDxteETcEBEBnF9oy8zM+sFauachaTSwO3ATsE1EPAEpsEjaOlfbHni0MNvSXFZVvrSkvGz5U0lXJOy4447drYxZF/a/5Hstp11x0OF92BOzdaProCFpM+AS4JiI+F3FbYeyCdFB+ZqFEdOB6QBjx44trWO2Nnzwkm+3nHblQUf0YU/M+kdX3wiX9EpSwLggIn6ci5/MQ0vkv0/l8qXADoXZRwGPtykfVVJuZmb9pJvsKQEzgHsi4uuFSXOARgbUZODyQvmknEU1Dng2D2PNA/aWtHm+Ab43MC9Pe07SuLysSYW2zMysH3QzPPVO4B+AxZJuz2VfAE4DLpI0BXgEOCRPmwvsB/QAzwOHA0TEckmnAAtyvZMjYnl+fiRwHrAxcFV+mJlZP+k4aETE9ZTfdwAYX1I/gGkt2poJzCwpXwjs1mkfzcxs7fI3wks8eW75j9ptc6R/0M7MNmz+aXQzM6vNQcPMzGpz0DAzs9p8T8MGlf0uO77ltLkHnNaHPTEbnHylYWZmtTlomJlZbR6eMiv44I+/0XLalR85pg97YjYw+UrDzMxqc9AwM7PaPDxlth758MVzSsvnHPzhPu6Jbah8pWFmZrU5aJiZWW0enjIbRCZePK+0/PKD9+njnthg5SsNMzOrzUHDzMxqc9AwM7PafE/DBpTDL53Qctr3DvxpH/ZkcDrwkl+Ull960Hv6uCe2vnLQMLOXHXTJgtLySw56W635P3Ppo6XlZx64Q8d9soFlwAcNSROAbwJDgO9GhH/fej12wo9aX0l85RBfSex/8Y9Ky684+JA+7kn/mPXjZaXlkz8ystb8V/93+fzjP1pvfmtvQN/TkDQEOAfYF9gFOEzSLv3bKzOzDddAv9LYE+iJiAcAJM0GJgJ392uvzDZQf3vJvaXlFx30hj7uyfrpN18vP3Rt+9l0LvzkN8qHB7c5pt7wYF8Y6EFje6A4SLoUeHs/9cXMuvS1S39TWv65A7etNf/lP3q6tHziIVvVmv/G854qLR/38a0BuPO/niydvtuntgHgoW+U93/0Man/vzn94dLp2/7zTrX6186TZ5YnMmzzmb5LZFBE9NnCekvSIcA+EfGP+fU/AHtGxKeb6k0FpuaXrwfuK0zeCijf0zx9sE8fyH3zdE8faNN3ioj2N38iYsA+gHcA8wqvTwBO6GUbCz19w5w+kPvm6Z4+0Ke3egzoG+HAAmCMpJ0lDQMOBcp/G9rMzNa5AX1PIyJWSjoKmEdKuZ0ZEXf1c7fMzDZYAzpoAETEXGBuF01M9/QNdvpA7pune/pAn15qQN8INzOzgWWg39MwM7MBxEHDzMxqc9DoY5I2krSbpF0lbdTf/bH+JWk7Sa/q7360Iqntt9IkbSLplYXXr5d0rKSPrNvebXgkbdv0us/3n0EVNCS9rfimSpok6XJJZ0raosb8u0s6WNIbS6a9p+qR62wk6RhJZ0v6lKShhfmHSvpP0rfaZwE/AB6V9J/FD1yb/p1Xp16LeUeW/W5XDl53S1okaXHTY5GkBZJmS3pzm/bbfqVX0gGSPidpnfzv0ar2JW1SMd/O/Xjg+z5wr6SvrcuFSPpym+nvyPv+1vn1myT9N3B9Sd3mbX01MDpPex1wA/BaYJqkr/Sij1Xb77w281Z+9iUd1GK+YZL+rc72l7STpK3y83G5rwf2Yv22lrRpfr6xpBMlnSZpuzbzFQP3jKbJtfYfSW+RpLp9rWxrMN0Il3Qr8DcRsTwfyGcDnwbeAryR6u94TAT+CriF9FMlX4mI7xTa/knJPAG8GRgVEUMk/RD4E/BL0o8sPhwRR+f5zwBeDRwbEc/lsuHA14D/Bc4GTgSWA18HvgO8B+gB/jEiFki6NSL2qFj/53KfABo7SJCy5DYC3hcRP2+aZx/gSOAzLZodCuwG/EdE7F6x7Cvzunya9K18gHuAsyPiOknfAnYF/gcYD/wkIk4pzD8kIl5q1X6uMxk4uqn9MyPi/Brt/wn4cl6PPze1eyvwe2BKRCzJB76bgQtIP5T5QG5vTq5/BvCaPPvZEXGrpDG02X4V6yVgL+BvgBXATOB04N3Ar4HjIqIn131Fsf+SPkbar84HdiD9MkLjh6DuAb4TEfdV7TuSTgf2B24HXgdcAfxTfr/+KyL+2FT/yoj4YOH17yJieH5+CrBFRExT+m7VLRHxVzX6/jWqt1+7fb/dZ//VwJ+Bf4qIB/M8+wJnAD8F9qD19r8ZeB74OOnzNJu0ra4jHSvuAL4ETKNi+0m6Bvh4RDySTyBHAvcCEyLifZLeQfrppF9ExFOS3gQcD7w7Ilr+tnzef34PlH1+lPt8P7AzcCvwq/w+3xgRv2vVbkudfCNwoD6AOwrPzwG+WHh9O3BWyeNs4OH8xm6S624JLGizrHcBVwE3Ah/KZYsL04cCtxZeLyEH6aZ2huRp15M+8J8DHgMOIR3oPwDclOveC+xO2sHXeJS0/Wrg86SD3tMV6/IS8LsWj2V5Ha9v8358EHgQOJwUSN8CfCIvez/gTmBIrrsJ6WDSmHcX4NI27U8CbgPeRzpgjwDeTwryk6raz2X3ka7ubgB2bpp2W9O2OwU4Jz8flt+HvQrT7wYOAv4BuCyXtd1+bdbvZ6SD9Fm5/X8mHfw/CVxXqHcV8Mb8/ETSd5jOJZ2oPAF8kXQCdADwH8DjwDjSgW1zYIuSx73ARrnNzUknMWN68blbVHj+K+CAFp/JVn2fU2P7Ve77tPns57+HkQ7ipwCX5m325pLPbvP2X5y3ybC83/2OVceKobnvldsPmEw6zkwqPJ+Wnz8AXJn/Xkj6UvNJwJOkk6SNenkcvK1F+SbAe4EvkE4Mnsz7xbd61X5vKg/0R954Qws72XuK05rqCvj7vEP8ELi7afotLZYxPu8E1wIfaJp2a6vXwP0V/b6/sWPn1z1N0xs7/XPANXnZzY9rCvVHkA4eD5DOgLZss/z7KqYNIQWBO1vVyfWua3wAm8rfBPy8zXszDxjZpv0bgdEl5aPztJbtF1/nbf4oMKk4jeoD3/PNfSk8v764jaq2X5v1u6OwXz7SYvv/NenK5T35+b3AR/LzP5CuFndsmvevSQfrF/L+8GDJ44Xe9rep/g9IVwrHkg5EjQPqiMJ6VfX9/vzYsdBm8/ar3Pep8dnP+/KXSGflS4G/LNSpDHxN++ttTX27td32A3bK/Xob6SrlZmDHXL4gr//WuX6vA3fVvl8yfVPScezf8zZ5oDftD/gv9/XShcDPJT1NetN/CS+Psz6bnw8lXWYeB9wEHBzp8v0ZSY3hKwF/UXgN8F+ks6NngRMj4lcly3+zpMblnoCN82sBG0maFBHnF2eQ9PeknWlUobj5krFxSd8TEe9vtfJ5vPU44O9Il8i7R0RjvZdI2i/SlyWL8+xLOpiUijRkdIeks1rVybaNiDtK5l8kaRtgR0mLGoslvb+L8vOIiPL/nrPK8Ih4qKT9h/Iw3+iq9oGVuf4PJF0PfF/SfsCn8jyL8rjwY6Qhmp8BSBpB072/iBhXeLl1/lsc8mq1/aq8lNuOvP+2mv8VwHDSB/8l0g/OiXTGezurhiUbff25pOmkk6LS4cWmfR/Se/ny64j4cJu+f5J0Rjwa2Dsins/lu5CCSbu+/xH4S2BeHkYs237t9v0TqfjsS3oX8C1SQNiBFKx+koeUT6V6+wOMyPc3BAwv3OsQ6cr32fxelW6/iHhY0jdJZ/ivJJ20PCJpx/w+vCIinsptrJB0X0QsabW+vSXpo6Qh0LeQTiAWkI5/74qI8p/ubdVWjjyDhqRxwHbAzyLiD7nsL4HNSD+AeDTpxt1pEfFwYb6/btP0taSzkztYdd/gZe0+WJJ2AC4m7dC35DbeBmwMHEgaouohf2Dyc/Lr10bEppJua/XBz8v4A2k46XukM7OirYCDSWOZt+SysaT3ZP+IuL+q/+1IuiUi3tpqGuls9HrSmO+fSqotjYp7GjXab3fD+rLieyfpFcC/kYYHNibduD2atO/MbARASXsB3wUOj4ibmpY7jrQfvVfS87TZflWdk/QM8Itc/935eWP+d0XE5rneyaShsc1IQzDfk7Ql8GDk+wolbd9K+qy3ChqV+3403QfrVEXfLyINZVa5rGrfz+1Xffank+5n3FyovwlpGGgiaeir1fb/C9JQaJUDqbf9NiMFkefz601JQeShwjyQrshefl3j+FIMYqeThkmLziednH6bdM+k48/7oAsaVST9GXiKdGAtrnjjbPdNFfN29cFq3MiTNJ50Bibgroi4Ok+/kjQm+hjlQelhSXtHROMMaGQuX1ZYxhfL5s22AH4EjCHd2Aa4i3Rweywifl3V/3YKB701JpHu/8wgnem8AVhECl6/It1j2BY4NSJaZqIUDspl7bc8KCv998dDSWPp/1oyfRzpADYhv96IdKYZwK8j4o+S9iQNYZ5HGooAeCsp4PxdRNysNqmpxROUFv2svX9JegOwMlbdHG/cUL2grGngb4HPR8R5VcvolKTFrPl5Ipe9QLqP8JWIuKNF34e32v8K229Zm31/I+AI0rZbDMyIiJWF6avdhG9axhsj4p7er/lqbXR7fOh2/u+xehJMsPp2+CRpmHmv/Hg96R7YDcANEXFNVfurLWswBQ1VZw8NI50xtDKaNGy1glXZL43shykRsbAXyy8OETSWv3FEtEx5k3Q06cOxHekAdWFE3N5UR6Qzo6PyMl5BGnY5KyJObtO3K4AvRMSipvKxwEkR8aF269em/Vo7vVJGzVjSjvuO/BhOujndcohKKTtpG1b/p1yQxoQfJ50MTCNln8wB5pPep8+Rxugntun/UFLQPhx4hPTejiJdtZ1ICrrTSBk+kALuORFR/l97VrU7BDg0IsoO6LVIemdjOFTSAeQDY0TMK9SZXNVGRMxSi+wz0k3bVgeC1Q76Lfq3U8X8L2ff5ccafc9tDKdi+5Fu7Lfc91WRuZjb/5eI+M/8/JCI+FFh2pdJ2/kLrP75b2S/TYmIhXlbbh4RT+f5hpGOGcdGxBpp+oX2X95+64qk4wovG9tiGeme24Ml9bchjTwcS/rsDam9rMEUNJpJejUpdfBTpOyc4yrqXk+6hBtOeiOPAX5CChxfIt1Abd6pKoNK0/JHknb6UhHx9TzPTqTgcSgp++ZCYHZE3C/pWFIm0tRYlTb4WlIGyk9J2VKtTIuIbVqs++LIaZHrmqTXkALFO/PfEaQblR9vM19l0CON+68gnTmNJ91vc1irAAAIq0lEQVRMHAYcHRG3qzoldgrQSP8sTYkuHoBa9K/yoFcjaA0hXRFsD/w0Iu6UtD9pn9s4InZXm7TiNu1PIu3XnyVdLYmUdXQ6aejwkhaztk25bjpZa9YIOjuRbva2Sqm9nOrt127f/0SsSu0dCtwchRRdFVJ21ZS+m4fvnqf6838G6b7mH0hDyV8kfUdiASnb6g7abL8W70+jD2Po5fGlaf6yY8sWwD65r3ez6ipjL9J7ewP5ir/OSfHLyxqMQSPfvDqGlN7238AZEfHbip1bpIyPIXn+noh4XaG920kZFy13qoh4e6H+GssnZXecy+pXIS+LiP8oWY/dSTe03xTpeyC3kTK2nm6qN5J04+4HJU1vSjoo7hARpV/mbF7fTrTb6UnpqLuS7rXcRMp4ujEiVtRs/86I2K3FtMUAhYPGENLNxR0LAaDdScEWpGyaaGp7SF6H61g94DTWrfEdmsqDXo31O490g/ZmUu7/w6SgenxEXNZ4D0gZai/l8fhfRr7Po9VvZJfZmnTF81DTckfn9fhDi/kaB/2VEfGudutRsl5DSEHnJmDTsr7neovbbL92+360ChKN+RsHbjXdG8xtKyLekl+Xff6HkjKqeiTtQdrOh0bEpbnOebTZfm3ep8r9s3h86Q2lLzX/v/yy8f2M/2k3XFopOkjpGqgP0s3er5Cygf4VeE0v5r217HnjNfVSYlsuv7nNin68EvgQaXz6N6ShqgPytJZpr83TSGfN/0pKqfwq8GPgkyXzTQF+uBbe+8rvKZDOBheS7gtMJX2Rco3vrVS031M1rWyblW2jVtuP6pTk/61at1ynmOc/hBRAXt2L9buTlEFDbvv3pIy0qnUq7rPL8n76z6xKay0+7q5YdtW0WinXNdavOQ21Vop0q/275L0rftfoOdLQVeP572j/+a49PZfd29vt1+b96Splu03bt5H+lWvHbRQfgy3l9mFWZQ89D0xR4ZvzkYeAWniDVqX4NdL9yK9fy+r/d7xVSmXV8remgqQPkL589EHS2cps0qV48QzwxYomXsztbEEagvgY6edK9oiUwrcNcKnSt3CL2VPDSJkf3dosIqbnPhwRq8aM50s6PSIm5Hsyu5Iuj48DdpO0nHQjruXQXbZA0iej8C39vKwpeX0O1qr0Zlg93TlY/SZ62fa7W61Tol+sWrf8/OWMsEhn0w9GPkuu6cXIN2oj3Xy/P9ZMhXyDWqcVP0G60jsM+Cjpy2IXRv6nZZL+t2LZLadF/ZTrdraq6HsAu6p1unrz9mv2YrQZk5f0UqG9jZuWtRHwpzaf/xWSPltocrOm13W2X5VuU7ZLSXo/6QTmUtJwJJIuiYjSn1Wp1WaORIOCqrOHiJIhoMK8ldlLpJuG7VJiq5a/cUQcX7H8a0lDWZdExPIWdV6ifBihseN/g5R6Op10k/b3JW28j0L2VPQia6JKuzHjptejSPc09iL9fMWWETGiuc2m9rch7fgvUhL02n1A1SYllvQ9gR9TnhK9cawaOildt6Ztozzf8/l5RIt02JL+NeZv9PHlzD7VzNBS+gG7w0j3K06OiLPUYfbZ2pLvSbRMuY722WWN97eY4EJ+vVFE1Pr9tor2K99b0g3vVoL0cx+V26/N8rtN2W7OYIM05Po4aZj8wmgxPNdbgypodENtspfaBZV2O31fUEopfoF0aV6WUlx54Opy2e0OyieQgsQ7SQeNRrrtr0hDO7XOploFPa2ecrmIlGtfTLmstf3ymdmuud93RcTV3X6ga65XxwdVrUpLvZh0pXoYKRtwDul9eKzbg3a3lL44V5py3eokqZftV2UuDouIjkZVVCP7TdIxpBOalmoExW5TtpvnD+C3ser7Ki1P6nprUAUNSf9eMTmiRqaJWmQvkdL42qXEdr389VWNK7WjWZWp8cQ6WH67lMt2JwUt8/z74oShzkFV1RlaIg2NXkXKtruzt+33BZWnXD8TEWv8AnPTfJUnBSX1a2dO5vodZ79JeiQidmwxrauU627nL7RTvFJrXAVDByeUgy1olO0YjeyhLSNis162t1r2Ui6rSoldq8tfn7Q7KPfB8ovZN2ukXBbqtTopOIXVg85DEXFMnqfP1q3qoKqKDC3SzdrG8FjLq8xOD9pri8pTrhdHxOFt5qs8KSjUK82crNGvjrPfJD1KujrtJuW6q5TtvjSogkZRPtM4mnTAvgj4v5F/26XNfK8EJpAOEuNJP7Z3YZSkzZUFlW6Xv76rCqrreLmV91FazPPy9iNlEFUGnb5Yt6qDqtqkpXbb/tpahxbLnU53KdeVJwVa83fXzor8u2sdtN+r91bSI6QMpW5SrrtK2e5Lgy5oaM3soW/W2TFVnr10WayevdQ2qHS6/MGoKqiug2XVuhHdavsB/96boLO2163OQbWTwNib9tclST8lpaTfSRoau4GURlvrAFQjuaLqd9faZU7Wab/qO14bA/d0E9DXxglBXxlUKbdK6Y+N7KG/ipLsoQpfIF3Ofq5sjLdFUFktJbbL5Q8KLQ7KLbPW1pZ2B+5220/SJapI+YyI4et43XYEXkX6tvFjpB/HfKapzptVkVbcZly6TvvrTHSfcl31C9JByhRrHNSrfhmho/YjorJNpW+VAx2nXHebst1nBtWVxrrMHlK9lNh+y17qb3Wv1PpLne1XMW+frFvTQXUvUpZY3YNqv7ffi370OuV6oKt7pbuu5u9LgypoWP/p5qA80PX1urU6qPY2g6i37a+t/rdY5mdYCynXFe1vsJmLfc1Bw2wAqHNQrZtB1Gn7a3eN1lj+11m3KdcbbOZiX3PQMBsA6hxU66YVd9r+YLGhZi72lUF1I9xsfRURn21fa7WbpStV+F21tdT+eq0kc3GPDTVzcV1y0DBbf7TL8BkwN0v7mjMX+46Hp8xsvbchZy72NQcNMzOrrfQ/uZmZmZVx0DAzs9ocNMzMrDYHDTMzq81Bw8zMavv/fGWPmv69KPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c7424af28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt_ = sns.barplot(list(count.keys()), list(count.values()))\n",
    "plt_.set_xticklabels(plt_.get_xticklabels(), rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-surfing",
   "metadata": {},
   "source": [
    "### 7. Dataloader & Evaluate Model\n",
    "\n",
    "Check whether it works before training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "finished-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(npoints, X_, y_):\n",
    "    \"\"\"Function to load the data\"\"\"\n",
    "    to_ret = []\n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_] #subset the data\n",
    "        to_ret.append((name, lang, word_rep(name), tag_rep(lang)))\n",
    "    \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "heavy-scientist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Benshoofin',\n",
       "  'NNP',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([0])),\n",
       " ('Wednesday',\n",
       "  'NNP',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([0]))]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataloader\n",
    "dataloader(2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "rental-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, n_points, topk, X_, y_, device = device):\n",
    "    \"Evaluation function\"\n",
    "\n",
    "    net = net.eval().to(device)\n",
    "    data_ = dataloader(n_points, X_, y_)\n",
    "    correct = 0\n",
    "\n",
    "    #iterate\n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "        \n",
    "        name_ohe = name_ohe.to(device)\n",
    "        lang_rep = lang_rep.to(device)\n",
    "        \n",
    "        \n",
    "\n",
    "        #get the output\n",
    "        output = infer(net, name, device)\n",
    "        val, indices = output.topk(topk) #get the top k values\n",
    "        indices = indices.to(device) #convert to devices\n",
    "        \n",
    "        if lang_rep in indices:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct/n_points\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "accurate-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the evaluation function\n",
    "eval(net, 1000, 1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-arrangement",
   "metadata": {},
   "source": [
    "### 8. Batching pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "naughty-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a batched name rep\n",
    "\n",
    "def batched_name_rep(names, max_word_size):\n",
    "    rep = torch.zeros(max_word_size, len(names), n_letters)\n",
    "    for name_index, name in enumerate(names):\n",
    "        for letter_index, letter in enumerate(name):\n",
    "            pos = all_letters.find(letter)\n",
    "            rep[letter_index][name_index][pos] = 1\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "legal-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_char(name_reps):\n",
    "    name_reps = name_reps.view((-1, name_reps.size()[-1]))\n",
    "    for t in name_reps: \n",
    "        if torch.sum(t) == 0:\n",
    "            print('<pad>')\n",
    "        else:\n",
    "            index = t.argmax()\n",
    "            print(all_letters[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "tutorial-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_lang_rep(langs):\n",
    "    rep = torch.zeros([len(langs)], dtype=torch.long)\n",
    "    for index, lang in enumerate(langs):\n",
    "        rep[index] = tags.index(lang)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "stainless-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "def batched_dataloader(npoints, X_, y_, verbose=False, device = device):\n",
    "    names = []\n",
    "    langs = []\n",
    "    X_lengths = []\n",
    "    \n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_]\n",
    "        X_lengths.append(len(name))\n",
    "        names.append(name)\n",
    "        langs.append(lang)\n",
    "    max_length = max(X_lengths)\n",
    "    \n",
    "    names_rep = batched_name_rep(names, max_length).to(device)\n",
    "    langs_rep = batched_lang_rep(langs).to(device)\n",
    "    \n",
    "    padded_names_rep = torch.nn.utils.rnn.pack_padded_sequence(names_rep, X_lengths, enforce_sorted = False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(names_rep.shape, padded_names_rep.data.shape)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print(names)\n",
    "        print_char(names_rep)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print_char(padded_names_rep.data)\n",
    "        print('Lang Rep', langs_rep.data)\n",
    "        print('Batch sizes', padded_names_rep.batch_sizes)\n",
    "    \n",
    "    \n",
    "    return padded_names_rep.to(device), langs_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ethical-condition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "I\n",
      "e\n",
      "v\n",
      "a\n",
      "o\n",
      "u\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "out_ = batched_name_rep(['Beau', 'Ivo'], 5)\n",
    "print_char(out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "defined-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 2, 57]) torch.Size([9, 57])\n",
      "--\n",
      "['to', 'billion']\n",
      "t\n",
      "b\n",
      "o\n",
      "i\n",
      "<pad>\n",
      "l\n",
      "<pad>\n",
      "l\n",
      "<pad>\n",
      "i\n",
      "<pad>\n",
      "o\n",
      "<pad>\n",
      "n\n",
      "--\n",
      "b\n",
      "t\n",
      "i\n",
      "o\n",
      "l\n",
      "l\n",
      "i\n",
      "o\n",
      "n\n",
      "Lang Rep tensor([18, 32], device='cuda:1')\n",
      "Batch sizes tensor([2, 2, 1, 1, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.]], device='cuda:1'), batch_sizes=tensor([2, 2, 1, 1, 1, 1, 1]), sorted_indices=tensor([1, 0], device='cuda:1'), unsorted_indices=tensor([1, 0], device='cuda:1')),\n",
       " tensor([18, 32], device='cuda:1'))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataloader(2, X_train, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-emergency",
   "metadata": {},
   "source": [
    "### 9. Training\n",
    "#### 9.1 Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "individual-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic train function\n",
    "\n",
    "def train(net, opt, criterion, n_points):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    total_loss = 0\n",
    "    \n",
    "    data_ = dataloader(n_points, X_train, y_train)\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "        \n",
    "        hidden = net.init_hidden()\n",
    "\n",
    "        for i in range(name_ohe.size()[0]):\n",
    "            output, hidden = net(name_ohe[i:i+1], hidden)\n",
    "        loss = criterion(output, lang_rep)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    opt.step()       \n",
    "    return total_loss/n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "rough-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, n_points, device = device):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    batch_input, batch_groundtruth = batched_dataloader(n_points, X_train, y_train, False, device)\n",
    "    batch_input = batch_input.to(device)\n",
    "    batch_groundtruth = batch_groundtruth.to(device)\n",
    "    \n",
    "    output, hidden = net(batch_input)\n",
    "    \n",
    "    loss = criterion(output, batch_groundtruth)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-acrobat",
   "metadata": {},
   "source": [
    "#### 9.2 Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "tutorial-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNN_net(n_letters, n_hidden, n_tags) #.to(device)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-conversation",
   "metadata": {},
   "source": [
    "#### 9.3 Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "skilled-fraud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.92 s, sys: 368 ms, total: 5.29 s\n",
      "Wall time: 1.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.6930, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "#time for normal training\n",
    "train(net, opt, criterion, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-september",
   "metadata": {},
   "source": [
    "### 10. Full training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "digital-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            # print('Top-1:', eval(net, len(X_test), 1, X_test, y_test), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test))\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    print('Top-1 Accuracy:', eval(net, len(X_test), 1, X_test, y_test, device), 'Top-2 Accuracy:', eval(net, len(X_test), 2, X_test, y_test, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "unsigned-representation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2999 Loss 0.3721696436405182\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGuFJREFUeJzt3X+UXGWd5/H3J91NEiQJkHQ0JGDDGKLgSsA2wvJj+DVA0IFVWQddEQY8kRkBcdwDAbMcZWBA5qwzMuxRUBEURFcQYYQMMkwYiAMJHTaJCRlCBAYigTQEQjJIkx/f/aNuV6orVdXVnb71635e59Tpqnufqv7eVKc//dznuU8pIjAzMwMYVe8CzMyscTgUzMwsz6FgZmZ5DgUzM8tzKJiZWZ5DwczM8hwKZmaW51AwM7M8h4KZmeW117uAoZo0aVJ0dXXVuwwzs6ayZMmSVyOic7B2TRcKXV1d9PT01LsMM7OmIuk/qmnn00dmZpbnUDAzszyHgpmZ5TkUzMwsz6FgZmZ5mQmF9W++zadvfIz1m96udylmZg0rM6Fw/UPPsPi5DXz8+oUOBjOzMpruOoWhmjFvPn1bt+cfr9/Ux6yrH2J0+yievmp2HSszM2s8Ld9TePSS4xilnbf3bd3OjHnza1+QmVkDa/lQmDx+TNl9UcM6zMyaQcuHAsAx0yex+25tA7Z1TdydhZceV6eKzMwaUyZC4ZZzP8qEsR0Dtm3bHkweV74XYWaWRZkIhRnz5rNu48AZRy++/gePKZiZFclEKDx6yXGcdsg++cdtgtNn7sOjPn1kZjZAy09JBTj6ugUDpqVuC7hn6Uv804qXPS3VzKxAZnoK75kwOv+4bZSYMmGMewpmZkUyEQqTx4/hhPe/O/942/bghPdP9kCzmVmR1EJB0hhJiyUtk7RS0jdKtDlHUq+kpcntC2nV8+rmPtqSi9imT96D3s19aX0rM7OmleaYQh9wfERsltQBLJQ0PyIeL2r3s4i4IMU6dlrq4pn1m3lm/WZmzJvvMQUzswKp9RQiZ3PysCO51eUi4kcvOY7TZu5D/2oXYzpGefaRmVkJqY4pSGqTtBRYDzwYEYtKNPuUpOWS7pS0bxp1TB4/hnGj2wlglHLrHo0b3e4xBTOzIqmGQkRsi4iZwDRglqQPFjX5R6ArIj4E/DNwa6nXkTRHUo+knt7e3mHV8urmPvYa28Huu7XxyUOneUzBzKyEmsw+iog3gIeBU4q2vxYR/b+dvwd8uMzzb4qI7ojo7uzsHFYNN57VTUfbKDb3bWNsxyhuPKt7WK9jZtbKUhtoltQJbImINySNBU4EvlnUZkpErEsengasSqOW4oHm2xa9wG2LXvBnKpiZFUmzpzAFWCBpOfAEuTGFX0m6UtJpSZuLkumqy4CLgHPSKKR/oLn/cxU80GxmVlpqPYWIWA4cWmL7FQX3LwMuS6uGfv0DzduTuU9vb/FAs5lZKZm4ohlyA83jRucy0BevmZmVlolQmDFvPg+sfIVNfVuB3MVrD6x8xUtnm5kVyUQoFI8pjG6XxxTMzErIRCgUjyn0bQ2PKZiZlZCJUJgxbz63L3phwLbbFr3g00dmZkUyEQrFax/5k9fMzErzJ6/54jUzs7zM9BQKP3kN8CevmZmVkIlQOPq6Bby8ceB1Ces2vs3R31xQp4rMzBpTJkKhv6fQPyUVYPfd2txTMDMrkolQmDx+DOvf7MtPSQV4651tzLr6Ic9AMjMrkIlQADhm+iT2mTDwugTPQDIzGygzofDYsxt4aePbA7bds/QljyuYmRXITCg8eslxTB63YwbSKHkGkplZscyEwuTxY/jjA3d8atv2gBPeP9lLXZiZFchMKMyYN5+fL1k7YJuXujAzGygzodC/1EU/L3VhZrazTCxzAV7qwsysGpnqKXipCzOzyjITCl7qwsxscJkJBfcUzMwGl1ooSBojabGkZZJWSvpGiTajJf1M0hpJiyR1pVWPewpmZoNLs6fQBxwfEYcAM4FTJB1e1OY84PWIeB/wd8A30yrGPQUzs8GlFgqRszl52JHcoqjZ6cCtyf07gRMkiRS4p2BmNrhUxxQktUlaCqwHHoyIRUVNpgIvAkTEVmAjMDGNWtxTMDMbXKqhEBHbImImMA2YJemDRU1K9QqKexNImiOpR1JPb2/vsGpxT8HMbHA1mX0UEW8ADwOnFO1aC+wLIKkdmABsKPH8myKiOyK6Ozs7i3dXxT0FM7PBpTn7qFPSnsn9scCJwL8XNbsXODu5fwbwLxGxU09hJLinYGY2uDR7ClOABZKWA0+QG1P4laQrJZ2WtPkBMFHSGuCvgLlpFeOegpnZ4JTSH+ap6e7ujp6eniE/b8a8+QPWPuo3un2U1z4ys5YnaUlEdA/WLnNXNI8qGNrefbc29xTMzApkJhQmjx/D+jf72F7QMXrrnW3Muvohf6aCmVkiM6EAcMz0SUzdc+yAbf5MBTOzHTIVCo89u4Hfv/GHAdvuWfqSZyCZmSUyFQqPXnIc7xnvGUhmZuVkKhSOvm4BL7/paxXMzMrJVCiUm33bXJNyzczSk6lQWHjpcXRN3H3Atq6Ju7PQp4/MzICMhcLR1y3g+dfeGrDt+dfe8ukjM7NEpkLBS12YmVWWqVDwonhmZpVlKhQ80GxmVlmmQsEDzWZmlWUqFDzQbGZWWaZCwaePzMwqy1QolDp9NG2vsT59ZGaWyFQolDp9tPb1P/j0kZlZIlOh8OglpXsEfVu3+zMVzMzIWChMHj+GTx46daft/kwFM7OcTIUCwC+X/n6nbf5MBTOznNRCQdK+khZIWiVppaQvl2hzrKSNkpYmtyvSqqdf+6jSh+wZSGZm0J7ia28FvhoRT0oaByyR9GBEPFXU7tGI+HiKdZiZWZVS6ylExLqIeDK5vwlYBex8Qr/GFl56HGM72gZs272jzdNSzcyo0ZiCpC7gUGBRid1HSFomab6kg9Ou5ejrFvCHLdsGbHtryzaPKZiZke7pIwAk7QHcBVwcEW8W7X4SeG9EbJZ0KvBLYHqJ15gDzAHYb7/9dqkeX9VsZlZeqj0FSR3kAuH2iPhF8f6IeDMiNif37wc6JE0q0e6miOiOiO7Ozs40SzYzy7Q0Zx8J+AGwKiK+VabNe5J2SJqV1PNaWjWZmVllafYUjgTOAo4vmHJ6qqTzJZ2ftDkDWCFpGXA9cGZEuRM8I8MDzWZm5Snl38Ejrru7O3p6eob9/Bnz5tO3dftO20e3j+Lpq2bvSmlmZg1L0pKI6B6sXeauaPZAs5lZeZkLhYWXHodKbH/Hi+KZmWUvFCaPH1O2V+DegpllXeZCAWBUqa6CmZllMxTKLYpnZpZ1/u1oZmZ5DgUzM8tzKJiZWZ5DwczM8hwKZmaW51AwM7O8TIZCucXvfFWzmWVdJkNh8vgxZff5qmYzy7KqQkHSH0kandw/VtJFkvZMt7T6eKfECqpmZllRbU/hLmCbpPeR++Cc/YGfpFZVDXS0lV7rotx2M7MsqDYUtkfEVuATwN9HxFeAKemVlT6VXCsVkg+CMzPLpGpDYYukzwBnA79KtnWkU5KZmdVLtaHw58ARwNUR8Zyk/YHb0isrfe9sKz124DEFM8uyqkIhIp6KiIsi4g5JewHjIuLalGtL1f0XHVV2n6elmllWVTv76GFJ4yXtDSwDfijpW+mWlq6D9plQdp+npZpZVlV7+mhCRLwJfBL4YUR8GDgxvbLMzKweqg2FdklTgE+zY6C5Ikn7SlogaZWklZK+XKKNJF0vaY2k5ZIOG0LtqfG4gpllVbWhcCXwAPC7iHhC0gHAM4M8Zyvw1Yj4AHA48CVJBxW1mQ1MT25zgO9UXfkI8LUKZmYDtVfTKCJ+Dvy84PGzwKcGec46YF1yf5OkVcBU4KmCZqcDP4qIAB6XtKekKclzU7dlW+nRg3LbzcxaXbUDzdMk3S1pvaRXJN0laVq130RSF3AosKho11TgxYLHa5NtNeGegpnZQNWePvohcC+wD7lf2v+YbBuUpD3ILZNxcTJYPWB3iafs9Ge6pDmSeiT19Pb2VllyFbWVuap5y7bwtFQzy6RqQ6EzIn4YEVuT2y1A52BPktRBLhBuj4hflGiyFti34PE04KXiRhFxU0R0R0R3Z+eg37Zq5ZbQBujzYLOZZVC1ofCqpM9JaktunwNeq/QE5RYR+gGwKiLKXdNwL/D5ZBbS4cDGWo0nQOUltH0KycyyqKqBZuBc4Abg78id3vk3cktfVHIkcBbwW0lLk22XA/sBRMR3gfuBU4E1wFtVvGbNeLDZzLKo2tlHLwCnFW6TdDHw9xWes5DSYwaFbQL4UjU1mJlZ+nblk9f+asSqMDOzhrArodASJ929MJ6Z2Q67EgotcdK90sJ4noFkZllTcUxB0iZK//IXMDaViszMrG4qhkJEjKtVIWZmVn+7cvrIzMxajEOByheqdc29r4aVmJnVl0MB+M2lx9e7BDOzhuBQoPJyF2ZmWeJQMDOzPIdCFXwRm5llhUMhUenKZl/EZmZZ4VBIVLqy2cwsKxwKZmaW51Ao4OsVzCzrHAoFfL2CmWWdQ6GAr1cws6xzKBT50NTxZff5FJKZtTqHQpF7Lzy63iWYmdWNQ8HMzPIcCiX8w2dmlt3nU0hm1spSCwVJN0taL2lFmf3HStooaWlyuyKtWobqTw+ZWu8SzMzqIs2ewi3AKYO0eTQiZia3K1OsZUR5LSQza1WphUJEPAJsSOv103bbebPK7vNaSGbWquo9pnCEpGWS5ks6uFwjSXMk9Ujq6e3trUlhR03vrMn3MTNrJPUMhSeB90bEIcA/AL8s1zAiboqI7ojo7uxsjF/WPoVkZq2obqEQEW9GxObk/v1Ah6RJ9aqnFC+nbWZZU7dQkPQeSUruz0pqea1e9ZTi5bTNLGvSnJJ6B/AYMEPSWknnSTpf0vlJkzOAFZKWAdcDZ0ZEpFVPGnzNgpm1mva0XjgiPjPI/huAG9L6/iNl8eUnMOtvHqp3GWZmNVHv2UcNb7CVU91bMLNW4lCowrEHNtT4t5lZahwKVbjl3I9W3O/egpm1CodClY44YO96l2BmljqHQpXumHNExf3uLZhZK3AoDMHEd+1W7xLMzFLlUBiCJf/rTyrud2/BzJqdQ2GIPBPJzFqZQ2GIPBPJzFqZQ2EYTj743RX3ewVVM2tWDoVhuPGs7or7vYKqmTUrh8IwPX/txyru92kkM2tGDoUUrd/0dr1LMDMbEofCLhistzDraq+uambNxaGwi3Zrr/xP2DX3Pg88m1nTcCjsotVXzR60jQeezaxZOBRGwGCnkcADz2bWHBwKI2SwaxfAwWBmjc+hMEJuPKvbPQYza3oOhRHmYDCzZpZaKEi6WdJ6SSvK7Jek6yWtkbRc0mFp1VJrPpVkZs0qzZ7CLcApFfbPBqYntznAd1KspaZuPKubyeNGD9rOwWBmjSa1UIiIR4ANFZqcDvwoch4H9pQ0Ja16am3x104c9BoGcDCYWWOp55jCVODFgsdrk20tY/VVs5EGb9c19z6eWrcx/YLMzAZRz1Ao9esySjaU5kjqkdTT29ubclkj67lrPlZVj+HUby/kxn99pgYVmZmVV89QWAvsW/B4GvBSqYYRcVNEdEdEd2dnZ02KG0mrr5pdVTBcM3+1TyeZWV3VMxTuBT6fzEI6HNgYEevqWE+qVl81u6rBZ8idTvrJoufTLcjMrIQ0p6TeATwGzJC0VtJ5ks6XdH7S5H7gWWAN8D3gL9OqpVEs/tqJVU1XBbj87pV8+adLUq7IzGwgRZQ8jd+wuru7o6enp95l7LKhnCb6m08czGc/2pVeMWbW8iQtiYjKHxuJr2ium2qufO53+d0r6Zp7HwvXNNcgu5k1H4dCHT1/7ceqmrLa73PfX8yH//rX/kQ3M0uNQ6HOnrvmY0PqNbz2n1uYdfVDHm8ws1Q4FBrEUIIB4J6lL9M19z73HMxsRHmguQEN51qF9lHi3guP5KApE1KoyMyanQeam9hQxxoAtm4PTv32Ql/jYGa7xD2FBrcrVzhPfFcH8y8+hsnjxoxgRWbWjKrtKTgUmsSuLn9x7pH7ccWf/pcRqsbMmo1DoUWNxNpIDgiz7HEotLiRWjjvzI9M5dpPzRyR1zKzxuVQyIiRXFVVwI+/MIuj3td8K9GaWWUOhYxJY8ltD1SbtQ6HQoal9ZkMDgmz5uVQMGZd/c+s39SX6ve4bPaBfPGPp6f6Pcxs1zkUbIBaBEQ/B4VZ43EoWFlf/HEPD6x8pabf09NgzerLoWBVq+fnQrtXYVYbDgUbtnqGRKHbPD3WbMQ4FGzENEpIFLrhszP5+Iem1rsMs6bhULDUHDhvPu9s3V7vMiry51qbDeRQsJra/7L7aLIfJS48/gC+etIH6l2GWU00RChIOgX4NtAGfD8iri3afw7wt8Dvk003RMT3K72mQ6F51HIabJp80Z61grqHgqQ2YDXwJ8Ba4AngMxHxVEGbc4DuiLig2td1KDS/ZuxVDJVPX1mjqTYU2lOsYRawJiKeTQr6KXA68FTFZ1nLe+6a8p9H3YiD2sNx+d0rufzulUN+nqfoWr2lGQpTgRcLHq8FPlqi3ackHUOuV/GViHixuIGkOcAcgP322y+FUq1RPH9t6wdGJdfMX80181cP+/k+1WW7Ks3TR/8dODkivpA8PguYFREXFrSZCGyOiD5J5wOfjojjK72uTx9ZOVkIjVrz1N/W0QhjCkcAX4+Ik5PHlwFExDVl2rcBGyJiQqXXdSjYrmiG6bRZ4YsTa6sRxhSeAKZL2p/c7KIzgc8WNpA0JSLWJQ9PA1alWI8Zq6+aXXVb9zzS9bnvL67Z93IAVS+1UIiIrZIuAB4gNyX15ohYKelKoCci7gUuknQasBXYAJyTVj1mQ1VpfKMUh0jjqmUAVdIM18b44jWzOsvCFF0bOcPt9dR9TCEtDgWznbmXkh3jx7Sz/OsnD/l5DgUzGxYHTPMYyinORhhoNrMmNNSxlKFw4IyMNsGt581K5bUdCmZWM2kGTrFWDqB3jW5PbTaVQ8HMWlItA6iSNK6NeTvFa20cCmZmKRrKtTGNYFS9CzAzs8bhUDAzszyHgpmZ5TkUzMwsz6FgZmZ5DgUzM8trumUuJPUC/zHMp08CXh3BcurJx9KYfCyNp1WOA3btWN4bEYNe8dZ0obArJPVUs/ZHM/CxNCYfS+NpleOA2hyLTx+ZmVmeQ8HMzPKyFgo31buAEeRjaUw+lsbTKscBNTiWTI0pmJlZZVnrKZiZWQWZCQVJp0h6WtIaSXPrXU81JD0v6beSlkrqSbbtLelBSc8kX/dKtkvS9cnxLZd0WJ1rv1nSekkrCrYNuXZJZyftn5F0doMcx9cl/T55X5ZKOrVg32XJcTwt6eSC7XX/+ZO0r6QFklZJWinpy8n2pnpfKhxH070vksZIWixpWXIs30i27y9pUfLv+zNJuyXbRyeP1yT7uwY7xiGLiJa/AW3A74ADgN2AZcBB9a6rirqfByYVbbsOmJvcnwt8M7l/KjAfEHA4sKjOtR8DHAasGG7twN7As8nXvZL7ezXAcXwd+J8l2h6U/GyNBvZPfubaGuXnD5gCHJbcHwesTmpuqvelwnE03fuS/NvukdzvABYl/9b/Fzgz2f5d4C+S+38JfDe5fybws0rHOJyastJTmAWsiYhnI+Id4KfA6XWuabhOB25N7t8K/LeC7T+KnMeBPSVNqUeBABHxCLChaPNQaz8ZeDAiNkTE68CDwCnpV79DmeMo53TgpxHRFxHPAWvI/ew1xM9fRKyLiCeT+5uAVcBUmux9qXAc5TTs+5L8225OHnYktwCOB+5Mthe/J/3v1Z3ACZJE+WMcsqyEwlTgxYLHa6n8Q9QoAvi1pCWS5iTb3h0R6yD3nwOYnGxvhmMcau2NfEwXJKdUbu4/3UITHUdy2uFQcn+ZNu37UnQc0ITvi6Q2SUuB9eQC9nfAGxGxtURd+ZqT/RuBiYzgsWQlFFRiWzNMuzoyIg4DZgNfknRMhbbNeoxQvvZGPabvAH8EzATWAf872d4UxyFpD+Au4OKIeLNS0xLbGuZ4ShxHU74vEbEtImYC08j9df+BUs2Sr6kfS1ZCYS2wb8HjacBLdaqlahHxUvJ1PXA3uR+YV/pPCyVf1yfNm+EYh1p7Qx5TRLyS/EfeDnyPHd30hj8OSR3kfpHeHhG/SDY33ftS6jia+X0BiIg3gIfJjSnsKan/45IL68rXnOyfQO705ogdS1ZC4QlgejKivxu5AZp761xTRZLeJWlc/33gJGAFubr7Z3ucDdyT3L8X+HwyY+RwYGP/KYEGMtTaHwBOkrRXcirgpGRbXRWN1XyC3PsCueM4M5khsj8wHVhMg/z8JeeefwCsiohvFexqqvel3HE04/siqVPSnsn9scCJ5MZIFgBnJM2K35P+9+oM4F8iN9Jc7hiHrpYj7fW8kZtJsZrc+bqv1bueKuo9gNxsgmXAyv6ayZ0/fAh4Jvm6d+yYxfB/kuP7LdBd5/rvINeF30Lur5jzhlM7cC65QbM1wJ83yHH8OKlzefKfcUpB+68lx/E0MLuRfv6Ao8idUlgOLE1upzbb+1LhOJrufQE+BPy/pOYVwBXJ9gPI/VJfA/wcGJ1sH5M8XpPsP2CwYxzqzVc0m5lZXlZOH5mZWRUcCmZmludQMDOzPIeCmZnlORTMzCzPoWCZJWlz8rVL0mdH+LUvL3r8byP5+mZpcSiYQRcwpFCQ1DZIkwGhEBH/dYg1mdWFQ8EMrgWOTtbg/0qyQNnfSnoiWVztiwCSjk3W8f8JuYukkPTLZMHClf2LFkq6FhibvN7tybb+XomS116h3Gdl/FnBaz8s6U5J/y7p9uTKXbOaah+8iVnLm0tuHf6PAyS/3DdGxEckjQZ+I+nXSdtZwAcjtzwxwLkRsSFZouAJSXdFxFxJF0RukbNinyS3YNshwKTkOY8k+w4FDia3Zs1vgCOBhSN/uGbluadgtrOTyK35s5TckswTya0lA7C4IBAALpK0DHic3IJk06nsKOCOyC3c9grwr8BHCl57beQWdFtK7rSWWU25p2C2MwEXRsSARd4kHQv8Z9HjE4EjIuItSQ+TW5tmsNcup6/g/jb8/9PqwD0FM9hE7mMd+z0A/EWyPDOSDkxWqi02AXg9CYT3k1vyuN+W/ucXeQT4s2TcopPcx30ObzVLsxT4LxGz3AqVW5PTQLcA3yZ36ubJZLC3lx0fh1jon4DzJS0ntzLl4wX7bgKWS3oyIv5Hwfa7gSPIrX4bwCUR8XISKmZ151VSzcwsz6ePzMwsz6FgZmZ5DgUzM8tzKJiZWZ5DwczM8hwKZmaW51AwM7M8h4KZmeX9f2APsq7TtenXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a38974860>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Top-1 Accuracy: 0.917979162196314 Top-2 Accuracy: 0.9770784159454498\n",
      "CPU times: user 55min 8s, sys: 1min, total: 56min 8s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#training RNN using batch technique\n",
    "net = RNN_net(n_letters, 128, n_tags)\n",
    "train_setup(net, lr=0.15, n_batches=3200, batch_size = 512, display_freq=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-doctor",
   "metadata": {},
   "source": [
    "### What I have learnt\n",
    "\n",
    "One interesting point that I got from this lab is that training in batches is possible despite its difficulty. In order to do so, padding is required, since words come in different length. Traning in batches enables the model to be trained on the GPU which boosts the speed of the traning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
