{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-quilt",
   "metadata": {},
   "source": [
    "### TASK2: Explore methods for batching patterns of different length prior to presentation to a RNN and implement them. See how much speedup you can get from the GPU with minibatch training.\n",
    "\n",
    "With minibatching, the training is expected to be faster as it enables the training on GPU.\n",
    "\n",
    "The code for batching is taken from the following link:\n",
    "\n",
    "https://github.com/Niranjankumar-c/DeepLearning-PadhAI/blob/master/DeepLearning_Materials/8_RNN_LSTM_Model/BatchingSeqModels.ipynb\n",
    "\n",
    "The results reported are as follows:\n",
    "\n",
    "Top-1 Accuracy: 0.7599003735990038 Top-2 Accuracy: 0.862266500622665 <br>\n",
    "CPU times: user 33min 58s, sys: 49.4 s, total: 34min 47s<br>\n",
    "Wall time: 6min 27s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moral-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda:1\n"
     ]
    }
   ],
   "source": [
    "from chosen_gpu import get_freer_gpu\n",
    "device = torch.device(get_freer_gpu()) \n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-providence",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "understood-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Arabic.txt', 'data/names/Chinese.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/English.txt', 'data/names/French.txt', 'data/names/German.txt', 'data/names/Greek.txt', 'data/names/Irish.txt', 'data/names/Italian.txt', 'data/names/Japanese.txt', 'data/names/Korean.txt', 'data/names/Polish.txt', 'data/names/Portuguese.txt', 'data/names/Russian.txt', 'data/names/Scottish.txt', 'data/names/Spanish.txt', 'data/names/Vietnamese.txt']\n"
     ]
    }
   ],
   "source": [
    "def findFiles(path):\n",
    "    return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-clause",
   "metadata": {},
   "source": [
    "#### 1.1 Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "practical-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-factory",
   "metadata": {},
   "source": [
    "#### 1.2 Build the category_lines dictionary, a list of names per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fixed-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic\n",
      "['Khoury', 'Nahas', 'Daher', 'Gerges', 'Nazari', 'Maalouf', 'Gerges', 'Naifeh', 'Guirguis', 'Baba', 'Sabbagh', 'Attia', 'Tahan', 'Haddad', 'Aswad', 'Najjar', 'Dagher', 'Maloof', 'Isa', 'Asghar', 'Nader', 'Gaber', 'Abboud', 'Maalouf', 'Zogby', 'Srour', 'Bahar', 'Mustafa', 'Hanania', 'Daher', 'Tuma', 'Nahas', 'Saliba', 'Shamoon', 'Handal', 'Baba', 'Amari', 'Bahar', 'Atiyeh', 'Said', 'Khouri', 'Tahan', 'Baba', 'Mustafa', 'Guirguis', 'Sleiman', 'Seif', 'Dagher', 'Bahar', 'Gaber', 'Harb', 'Seif', 'Asker', 'Nader', 'Antar', 'Awad', 'Srour', 'Shadid', 'Hajjar', 'Hanania', 'Kalb', 'Shadid', 'Bazzi', 'Mustafa', 'Masih', 'Ghanem', 'Haddad', 'Isa', 'Antoun', 'Sarraf', 'Sleiman', 'Dagher', 'Najjar', 'Malouf', 'Nahas', 'Naser', 'Saliba', 'Shamon', 'Malouf', 'Kalb', 'Daher', 'Maalouf', 'Wasem', 'Kanaan', 'Naifeh', 'Boutros', 'Moghadam', 'Masih', 'Sleiman', 'Aswad', 'Cham', 'Assaf', 'Quraishi', 'Shalhoub', 'Sabbag', 'Mifsud', 'Gaber', 'Shammas', 'Tannous', 'Sleiman', 'Bazzi', 'Quraishi', 'Rahal', 'Cham', 'Ghanem', 'Ghanem', 'Naser', 'Baba', 'Shamon', 'Almasi', 'Basara', 'Quraishi', 'Bata', 'Wasem', 'Shamoun', 'Deeb', 'Touma', 'Asfour', 'Deeb', 'Hadad', 'Naifeh', 'Touma', 'Bazzi', 'Shamoun', 'Nahas', 'Haddad', 'Arian', 'Kouri', 'Deeb', 'Toma', 'Halabi', 'Nazari', 'Saliba', 'Fakhoury', 'Hadad', 'Baba', 'Mansour', 'Sayegh', 'Antar', 'Deeb', 'Morcos', 'Shalhoub', 'Sarraf', 'Amari', 'Wasem', 'Ganim', 'Tuma', 'Fakhoury', 'Hadad', 'Hakimi', 'Nader', 'Said', 'Ganim', 'Daher', 'Ganem', 'Tuma', 'Boutros', 'Aswad', 'Sarkis', 'Daher', 'Toma', 'Boutros', 'Kanaan', 'Antar', 'Gerges', 'Kouri', 'Maroun', 'Wasem', 'Dagher', 'Naifeh', 'Bishara', 'Ba', 'Cham', 'Kalb', 'Bazzi', 'Bitar', 'Hadad', 'Moghadam', 'Sleiman', 'Shamoun', 'Antar', 'Atiyeh', 'Koury', 'Nahas', 'Kouri', 'Maroun', 'Nassar', 'Sayegh', 'Haik', 'Ghanem', 'Sayegh', 'Salib', 'Cham', 'Bata', 'Touma', 'Antoun', 'Antar', 'Bata', 'Botros', 'Shammas', 'Ganim', 'Sleiman', 'Seif', 'Moghadam', 'Ba', 'Tannous', 'Bazzi', 'Seif', 'Salib', 'Hadad', 'Quraishi', 'Halabi', 'Essa', 'Bahar', 'Kattan', 'Boutros', 'Nahas', 'Sabbagh', 'Kanaan', 'Sayegh', 'Said', 'Botros', 'Najjar', 'Toma', 'Bata', 'Atiyeh', 'Halabi', 'Tannous', 'Kouri', 'Shamoon', 'Kassis', 'Haddad', 'Tuma', 'Mansour', 'Antar', 'Kassis', 'Kalb', 'Basara', 'Rahal', 'Mansour', 'Handal', 'Morcos', 'Fakhoury', 'Hadad', 'Morcos', 'Kouri', 'Quraishi', 'Almasi', 'Awad', 'Naifeh', 'Koury', 'Asker', 'Maroun', 'Fakhoury', 'Sabbag', 'Sarraf', 'Shamon', 'Assaf', 'Boutros', 'Malouf', 'Nassar', 'Qureshi', 'Ghanem', 'Srour', 'Almasi', 'Qureshi', 'Ghannam', 'Mustafa', 'Najjar', 'Kassab', 'Shadid', 'Shamoon', 'Morcos', 'Atiyeh', 'Isa', 'Ba', 'Baz', 'Asker', 'Seif', 'Asghar', 'Hajjar', 'Deeb', 'Essa', 'Qureshi', 'Abboud', 'Ganem', 'Haddad', 'Koury', 'Nassar', 'Abadi', 'Toma', 'Tannous', 'Harb', 'Issa', 'Khouri', 'Mifsud', 'Kalb', 'Gaber', 'Ganim', 'Boulos', 'Samaha', 'Haddad', 'Sabbag', 'Wasem', 'Dagher', 'Rahal', 'Atiyeh', 'Antar', 'Asghar', 'Mansour', 'Awad', 'Boulos', 'Sarraf', 'Deeb', 'Abadi', 'Nazari', 'Daher', 'Gerges', 'Shamoon', 'Gaber', 'Amari', 'Sarraf', 'Nazari', 'Saliba', 'Naifeh', 'Nazari', 'Hakimi', 'Shamon', 'Abboud', 'Quraishi', 'Tahan', 'Safar', 'Hajjar', 'Srour', 'Gaber', 'Shalhoub', 'Attia', 'Safar', 'Said', 'Ganem', 'Nader', 'Asghar', 'Mustafa', 'Said', 'Antar', 'Botros', 'Nader', 'Ghannam', 'Asfour', 'Tahan', 'Mansour', 'Attia', 'Touma', 'Najjar', 'Kassis', 'Abboud', 'Bishara', 'Bazzi', 'Shalhoub', 'Shalhoub', 'Safar', 'Khoury', 'Nazari', 'Sabbag', 'Sleiman', 'Atiyeh', 'Kouri', 'Bitar', 'Zogby', 'Ghanem', 'Assaf', 'Abadi', 'Arian', 'Shalhoub', 'Khoury', 'Morcos', 'Shamon', 'Wasem', 'Abadi', 'Antoun', 'Baz', 'Naser', 'Assaf', 'Saliba', 'Nader', 'Mikhail', 'Naser', 'Daher', 'Morcos', 'Awad', 'Nahas', 'Sarkis', 'Malouf', 'Mustafa', 'Fakhoury', 'Ghannam', 'Shadid', 'Gaber', 'Koury', 'Atiyeh', 'Shamon', 'Boutros', 'Sarraf', 'Arian', 'Fakhoury', 'Abadi', 'Kassab', 'Nahas', 'Quraishi', 'Mansour', 'Samaha', 'Wasem', 'Seif', 'Fakhoury', 'Saliba', 'Cham', 'Bahar', 'Shamoun', 'Essa', 'Shamon', 'Asfour', 'Bitar', 'Cham', 'Tahan', 'Tannous', 'Daher', 'Khoury', 'Shamon', 'Bahar', 'Quraishi', 'Ghannam', 'Kassab', 'Zogby', 'Basara', 'Shammas', 'Arian', 'Sayegh', 'Naifeh', 'Mifsud', 'Sleiman', 'Arian', 'Kassis', 'Shamoun', 'Kassis', 'Harb', 'Mustafa', 'Boulos', 'Asghar', 'Shamon', 'Kanaan', 'Atiyeh', 'Kassab', 'Tahan', 'Bazzi', 'Kassis', 'Qureshi', 'Basara', 'Shalhoub', 'Sayegh', 'Haik', 'Attia', 'Maroun', 'Kassis', 'Sarkis', 'Harb', 'Assaf', 'Kattan', 'Antar', 'Sleiman', 'Touma', 'Sarraf', 'Bazzi', 'Boulos', 'Baz', 'Issa', 'Shamon', 'Shadid', 'Deeb', 'Sabbag', 'Wasem', 'Awad', 'Mansour', 'Saliba', 'Fakhoury', 'Arian', 'Bishara', 'Dagher', 'Bishara', 'Koury', 'Fakhoury', 'Naser', 'Nader', 'Antar', 'Gerges', 'Handal', 'Hanania', 'Shadid', 'Gerges', 'Kassis', 'Essa', 'Assaf', 'Shadid', 'Seif', 'Shalhoub', 'Shamoun', 'Hajjar', 'Baba', 'Sayegh', 'Mustafa', 'Sabbagh', 'Isa', 'Najjar', 'Tannous', 'Hanania', 'Ganem', 'Gerges', 'Fakhoury', 'Mifsud', 'Nahas', 'Bishara', 'Bishara', 'Abadi', 'Sarkis', 'Masih', 'Isa', 'Attia', 'Kalb', 'Essa', 'Boulos', 'Basara', 'Halabi', 'Halabi', 'Dagher', 'Attia', 'Kassis', 'Tuma', 'Gerges', 'Ghannam', 'Toma', 'Baz', 'Asghar', 'Zogby', 'Aswad', 'Hadad', 'Dagher', 'Naser', 'Shadid', 'Atiyeh', 'Zogby', 'Abboud', 'Tannous', 'Khouri', 'Atiyeh', 'Ganem', 'Maalouf', 'Isa', 'Maroun', 'Issa', 'Khouri', 'Harb', 'Nader', 'Awad', 'Nahas', 'Said', 'Baba', 'Totah', 'Ganim', 'Handal', 'Mansour', 'Basara', 'Malouf', 'Said', 'Botros', 'Samaha', 'Safar', 'Tahan', 'Botros', 'Shamoun', 'Handal', 'Sarraf', 'Malouf', 'Bishara', 'Aswad', 'Khouri', 'Baz', 'Asker', 'Toma', 'Koury', 'Gerges', 'Bishara', 'Boulos', 'Najjar', 'Aswad', 'Shamon', 'Kouri', 'Srour', 'Assaf', 'Tannous', 'Attia', 'Mustafa', 'Kattan', 'Asghar', 'Amari', 'Shadid', 'Said', 'Bazzi', 'Masih', 'Antar', 'Fakhoury', 'Shadid', 'Masih', 'Handal', 'Sarraf', 'Kassis', 'Salib', 'Hajjar', 'Totah', 'Koury', 'Totah', 'Mustafa', 'Sabbagh', 'Moghadam', 'Toma', 'Srour', 'Almasi', 'Totah', 'Maroun', 'Kattan', 'Naifeh', 'Sarkis', 'Mikhail', 'Nazari', 'Boutros', 'Guirguis', 'Gaber', 'Kassis', 'Masih', 'Hanania', 'Maloof', 'Quraishi', 'Cham', 'Hadad', 'Tahan', 'Bitar', 'Arian', 'Gaber', 'Baz', 'Mansour', 'Kalb', 'Sarkis', 'Attia', 'Antar', 'Asfour', 'Said', 'Essa', 'Koury', 'Hadad', 'Tuma', 'Moghadam', 'Sabbagh', 'Amari', 'Dagher', 'Srour', 'Antoun', 'Sleiman', 'Maroun', 'Tuma', 'Nahas', 'Hanania', 'Sayegh', 'Amari', 'Sabbagh', 'Said', 'Cham', 'Asker', 'Nassar', 'Bitar', 'Said', 'Dagher', 'Safar', 'Khouri', 'Totah', 'Khoury', 'Salib', 'Basara', 'Abboud', 'Baz', 'Isa', 'Cham', 'Amari', 'Mifsud', 'Hadad', 'Rahal', 'Khoury', 'Bazzi', 'Basara', 'Totah', 'Ghannam', 'Koury', 'Malouf', 'Zogby', 'Zogby', 'Boutros', 'Nassar', 'Handal', 'Hajjar', 'Maloof', 'Abadi', 'Maroun', 'Mifsud', 'Kalb', 'Amari', 'Hakimi', 'Boutros', 'Masih', 'Kattan', 'Haddad', 'Arian', 'Nazari', 'Assaf', 'Attia', 'Wasem', 'Gerges', 'Asker', 'Tahan', 'Fakhoury', 'Shadid', 'Sarraf', 'Attia', 'Naifeh', 'Aswad', 'Deeb', 'Tannous', 'Totah', 'Cham', 'Baba', 'Najjar', 'Hajjar', 'Shamoon', 'Handal', 'Awad', 'Guirguis', 'Awad', 'Ganem', 'Naifeh', 'Khoury', 'Hajjar', 'Moghadam', 'Mikhail', 'Ghannam', 'Guirguis', 'Tannous', 'Kanaan', 'Handal', 'Khoury', 'Kalb', 'Qureshi', 'Najjar', 'Atiyeh', 'Gerges', 'Nassar', 'Tahan', 'Hadad', 'Fakhoury', 'Salib', 'Wasem', 'Bitar', 'Fakhoury', 'Attia', 'Awad', 'Totah', 'Deeb', 'Touma', 'Botros', 'Nazari', 'Nahas', 'Kouri', 'Ghannam', 'Assaf', 'Asfour', 'Sarraf', 'Naifeh', 'Toma', 'Asghar', 'Abboud', 'Issa', 'Sabbag', 'Sabbagh', 'Isa', 'Koury', 'Kattan', 'Shamoon', 'Rahal', 'Kalb', 'Naser', 'Masih', 'Sayegh', 'Dagher', 'Asker', 'Maroun', 'Dagher', 'Sleiman', 'Botros', 'Sleiman', 'Harb', 'Tahan', 'Tuma', 'Said', 'Hadad', 'Samaha', 'Harb', 'Cham', 'Atiyeh', 'Haik', 'Malouf', 'Bazzi', 'Harb', 'Malouf', 'Ghanem', 'Cham', 'Asghar', 'Samaha', 'Khouri', 'Nassar', 'Rahal', 'Baz', 'Kalb', 'Rahal', 'Gerges', 'Cham', 'Sayegh', 'Shadid', 'Morcos', 'Shamoon', 'Hakimi', 'Shamoon', 'Qureshi', 'Ganim', 'Shadid', 'Khoury', 'Boutros', 'Hanania', 'Antoun', 'Naifeh', 'Deeb', 'Samaha', 'Awad', 'Asghar', 'Awad', 'Saliba', 'Shamoun', 'Mikhail', 'Hakimi', 'Mikhail', 'Cham', 'Halabi', 'Sarkis', 'Kattan', 'Nazari', 'Safar', 'Morcos', 'Khoury', 'Essa', 'Nassar', 'Haik', 'Shadid', 'Fakhoury', 'Najjar', 'Arian', 'Botros', 'Daher', 'Saliba', 'Saliba', 'Kattan', 'Hajjar', 'Nader', 'Daher', 'Nassar', 'Maroun', 'Harb', 'Nassar', 'Antar', 'Shammas', 'Toma', 'Antar', 'Koury', 'Nader', 'Botros', 'Bahar', 'Najjar', 'Maloof', 'Salib', 'Malouf', 'Mansour', 'Bazzi', 'Atiyeh', 'Kanaan', 'Bishara', 'Hakimi', 'Saliba', 'Tuma', 'Mifsud', 'Hakimi', 'Assaf', 'Nassar', 'Sarkis', 'Bitar', 'Isa', 'Halabi', 'Shamon', 'Qureshi', 'Bishara', 'Maalouf', 'Srour', 'Boulos', 'Safar', 'Shamoun', 'Ganim', 'Abadi', 'Koury', 'Shadid', 'Zogby', 'Boutros', 'Shadid', 'Hakimi', 'Bazzi', 'Isa', 'Totah', 'Salib', 'Shamoon', 'Gaber', 'Antar', 'Antar', 'Najjar', 'Fakhoury', 'Malouf', 'Salib', 'Rahal', 'Boulos', 'Attia', 'Said', 'Kassis', 'Bahar', 'Bazzi', 'Srour', 'Antar', 'Nahas', 'Kassis', 'Samaha', 'Quraishi', 'Asghar', 'Asker', 'Antar', 'Totah', 'Haddad', 'Maloof', 'Kouri', 'Basara', 'Bata', 'Antar', 'Shammas', 'Arian', 'Gerges', 'Seif', 'Almasi', 'Tuma', 'Shamoon', 'Khoury', 'Hakimi', 'Abboud', 'Baz', 'Seif', 'Issa', 'Nazari', 'Harb', 'Shammas', 'Amari', 'Totah', 'Malouf', 'Sarkis', 'Naser', 'Zogby', 'Handal', 'Naifeh', 'Cham', 'Hadad', 'Gerges', 'Kalb', 'Shalhoub', 'Saliba', 'Tannous', 'Tahan', 'Tannous', 'Kassis', 'Shadid', 'Sabbag', 'Tahan', 'Abboud', 'Nahas', 'Shamoun', 'Dagher', 'Botros', 'Amari', 'Maalouf', 'Awad', 'Gerges', 'Shamoon', 'Haddad', 'Salib', 'Attia', 'Kassis', 'Sleiman', 'Maloof', 'Maroun', 'Koury', 'Asghar', 'Kalb', 'Asghar', 'Touma', 'Ganim', 'Rahal', 'Haddad', 'Zogby', 'Mansour', 'Guirguis', 'Touma', 'Maroun', 'Tannous', 'Hakimi', 'Baba', 'Toma', 'Botros', 'Sarraf', 'Koury', 'Sarraf', 'Nassar', 'Boutros', 'Guirguis', 'Qureshi', 'Aswad', 'Basara', 'Toma', 'Tuma', 'Mansour', 'Ba', 'Naifeh', 'Mikhail', 'Amari', 'Shamon', 'Malouf', 'Boutros', 'Hakimi', 'Srour', 'Morcos', 'Halabi', 'Bazzi', 'Abadi', 'Shamoun', 'Haddad', 'Baz', 'Baba', 'Hadad', 'Saliba', 'Haddad', 'Maalouf', 'Bitar', 'Shammas', 'Totah', 'Said', 'Najjar', 'Mikhail', 'Samaha', 'Boulos', 'Kalb', 'Shamon', 'Shamoun', 'Seif', 'Touma', 'Hajjar', 'Hadad', 'Atiyeh', 'Totah', 'Mansour', 'Nazari', 'Quraishi', 'Ba', 'Sarkis', 'Gerges', 'Shalhoub', 'Nazari', 'Issa', 'Salib', 'Shalhoub', 'Nassar', 'Guirguis', 'Daher', 'Hakimi', 'Attia', 'Cham', 'Isa', 'Hakimi', 'Amari', 'Boutros', 'Sarraf', 'Antoun', 'Botros', 'Haddad', 'Tahan', 'Bishara', 'Shalhoub', 'Safar', 'Haik', 'Tahan', 'Seif', 'Awad', 'Antoun', 'Atiyeh', 'Samaha', 'Assaf', 'Guirguis', 'Hadad', 'Sayegh', 'Khouri', 'Asghar', 'Tannous', 'Maalouf', 'Khouri', 'Hajjar', 'Abadi', 'Ghanem', 'Salib', 'Botros', 'Bitar', 'Bishara', 'Quraishi', 'Boutros', 'Aswad', 'Srour', 'Shamon', 'Abboud', 'Almasi', 'Baba', 'Tahan', 'Essa', 'Sabbag', 'Issa', 'Abadi', 'Abboud', 'Bazzi', 'Nader', 'Bahar', 'Ghannam', 'Asghar', 'Gaber', 'Sayegh', 'Guirguis', 'Srour', 'Asghar', 'Quraishi', 'Sayegh', 'Rahal', 'Tahan', 'Morcos', 'Cham', 'Kanaan', 'Nahas', 'Essa', 'Mifsud', 'Kouri', 'Isa', 'Saliba', 'Asfour', 'Guirguis', 'Isa', 'Bishara', 'Assaf', 'Naser', 'Moghadam', 'Kalb', 'Baba', 'Guirguis', 'Naifeh', 'Bitar', 'Samaha', 'Abboud', 'Hadad', 'Ghannam', 'Hanania', 'Shadid', 'Totah', 'Tahan', 'Toma', 'Maloof', 'Botros', 'Issa', 'Deeb', 'Nahas', 'Khoury', 'Sayegh', 'Harb', 'Said', 'Guirguis', 'Nader', 'Harb', 'Atiyeh', 'Zogby', 'Basara', 'Nassar', 'Kalb', 'Khoury', 'Mifsud', 'Wasem', 'Handal', 'Ganim', 'Harb', 'Ganim', 'Malouf', 'Sayegh', 'Khoury', 'Sabbag', 'Sabbag', 'Boulos', 'Malouf', 'Gaber', 'Shammas', 'Fakhoury', 'Halabi', 'Haddad', 'Asker', 'Morcos', 'Hanania', 'Amari', 'Kassab', 'Malouf', 'Khouri', 'Moghadam', 'Totah', 'Maloof', 'Atiyeh', 'Abadi', 'Baz', 'Khoury', 'Arian', 'Handal', 'Dagher', 'Awad', 'Atiyeh', 'Arian', 'Khoury', 'Amari', 'Attia', 'Ganim', 'Nader', 'Dagher', 'Sabbag', 'Halabi', 'Khouri', 'Khouri', 'Saliba', 'Mifsud', 'Koury', 'Awad', 'Bahar', 'Mustafa', 'Kassis', 'Gaber', 'Mifsud', 'Bishara', 'Asker', 'Nahas', 'Wasem', 'Sleiman', 'Bata', 'Daher', 'Antar', 'Isa', 'Ganim', 'Rahal', 'Toma', 'Rahal', 'Shamoun', 'Maloof', 'Hakimi', 'Safar', 'Gerges', 'Hanania', 'Koury', 'Assaf', 'Safar', 'Gerges', 'Ganim', 'Morcos', 'Awad', 'Arian', 'Tahan', 'Sleiman', 'Asker', 'Boulos', 'Koury', 'Mifsud', 'Sabbag', 'Dagher', 'Bazzi', 'Mustafa', 'Almasi', 'Handal', 'Isa', 'Guirguis', 'Sayegh', 'Ganim', 'Ghanem', 'Toma', 'Mustafa', 'Basara', 'Bitar', 'Samaha', 'Mifsud', 'Tahan', 'Issa', 'Salib', 'Khoury', 'Hadad', 'Haik', 'Gaber', 'Mansour', 'Hakimi', 'Ba', 'Mustafa', 'Gaber', 'Kattan', 'Koury', 'Awad', 'Maalouf', 'Masih', 'Harb', 'Atiyeh', 'Zogby', 'Nahas', 'Assaf', 'Morcos', 'Ganem', 'Ganem', 'Wasem', 'Fakhoury', 'Ghanem', 'Salib', 'Khouri', 'Maloof', 'Khouri', 'Shalhoub', 'Issa', 'Najjar', 'Kassis', 'Mustafa', 'Sayegh', 'Kassis', 'Hajjar', 'Nader', 'Sarkis', 'Tahan', 'Haddad', 'Antar', 'Sayegh', 'Zogby', 'Mifsud', 'Kassab', 'Hanania', 'Bishara', 'Shamoun', 'Abboud', 'Mustafa', 'Sleiman', 'Abadi', 'Sarraf', 'Zogby', 'Daher', 'Issa', 'Nazari', 'Shamon', 'Tuma', 'Asghar', 'Morcos', 'Mifsud', 'Cham', 'Sarraf', 'Antar', 'Ba', 'Aswad', 'Mikhail', 'Kouri', 'Mikhail', 'Awad', 'Halabi', 'Moghadam', 'Mikhail', 'Naifeh', 'Kattan', 'Shammas', 'Malouf', 'Najjar', 'Srour', 'Masih', 'Fakhoury', 'Khouri', 'Assaf', 'Mifsud', 'Malouf', 'Abboud', 'Shamoon', 'Mansour', 'Halabi', 'Ganem', 'Deeb', 'Wasem', 'Kalb', 'Safar', 'Tuma', 'Fakhoury', 'Toma', 'Guirguis', 'Kassab', 'Nader', 'Handal', 'Baba', 'Fakhoury', 'Haik', 'Guirguis', 'Seif', 'Almasi', 'Shamon', 'Ba', 'Salib', 'Zogby', 'Koury', 'Najjar', 'Atiyeh', 'Morcos', 'Antar', 'Awad', 'Hadad', 'Maroun', 'Touma', 'Almasi', 'Kassis', 'Arian', 'Malouf', 'Koury', 'Sarraf', 'Hadad', 'Bata', 'Tuma', 'Sarkis', 'Quraishi', 'Gaber', 'Abadi', 'Nader', 'Bazzi', 'Ghannam', 'Botros', 'Deeb', 'Awad', 'Kattan', 'Kanaan', 'Sarraf', 'Nahas', 'Assaf', 'Shadid', 'Gaber', 'Samaha', 'Harb', 'Samaha', 'Zogby', 'Atiyeh', 'Mustafa', 'Hanania', 'Isa', 'Almasi', 'Bitar', 'Fakhoury', 'Moghadam', 'Handal', 'Seif', 'Mustafa', 'Rahal', 'Antoun', 'Kassab', 'Bazzi', 'Hadad', 'Nader', 'Tuma', 'Basara', 'Totah', 'Nassar', 'Seif', 'Nassar', 'Daher', 'Daher', 'Maalouf', 'Rahal', 'Quraishi', 'Hadad', 'Bahar', 'Sabbag', 'Halabi', 'Tuma', 'Antoun', 'Boutros', 'Gerges', 'Bishara', 'Baba', 'Zogby', 'Nahas', 'Atiyeh', 'Rahal', 'Sabbagh', 'Bitar', 'Botros', 'Tuma', 'Ganim', 'Handal', 'Daher', 'Boutros', 'Khouri', 'Maroun', 'Mifsud', 'Arian', 'Safar', 'Koury', 'Deeb', 'Shamoun', 'Cham', 'Asghar', 'Morcos', 'Tahan', 'Salib', 'Aswad', 'Shadid', 'Saliba', 'Ganim', 'Haik', 'Kattan', 'Antoun', 'Hajjar', 'Toma', 'Toma', 'Antoun', 'Tahan', 'Haik', 'Kassis', 'Shamoun', 'Shammas', 'Kassis', 'Shadid', 'Samaha', 'Sarraf', 'Nader', 'Ganem', 'Zogby', 'Maloof', 'Kalb', 'Gerges', 'Seif', 'Nahas', 'Arian', 'Asfour', 'Hakimi', 'Ba', 'Handal', 'Abadi', 'Harb', 'Nader', 'Asghar', 'Sabbag', 'Touma', 'Amari', 'Kanaan', 'Hajjar', 'Said', 'Sarraf', 'Haddad', 'Mifsud', 'Shammas', 'Sleiman', 'Asfour', 'Deeb', 'Kattan', 'Naser', 'Said', 'Bishara', 'Harb', 'Morcos', 'Sayegh', 'Said', 'Naser', 'Aswad', 'Seif', 'Kouri', 'Dagher', 'Shamon', 'Hadad', 'Handal', 'Tuma', 'Shamon', 'Hakimi', 'Rahal', 'Hadad', 'Ghannam', 'Almasi', 'Daher', 'Handal', 'Malouf', 'Mansour', 'Sabbagh', 'Sabbag', 'Saliba', 'Haddad', 'Tahan', 'Khoury', 'Harb', 'Ganim', 'Mansour', 'Ganem', 'Handal', 'Handal', 'Antar', 'Asfour', 'Kouri', 'Cham', 'Masih', 'Saliba', 'Qureshi', 'Daher', 'Safar', 'Assaf', 'Harb', 'Abboud', 'Haik', 'Ghannam', 'Maalouf', 'Daher', 'Najjar', 'Mifsud', 'Daher', 'Amari', 'Saliba', 'Kanaan', 'Guirguis', 'Atiyeh', 'Sleiman', 'Mikhail', 'Arian', 'Wasem', 'Attia', 'Nassar', 'Cham', 'Koury', 'Baba', 'Guirguis', 'Morcos', 'Quraishi', 'Seif', 'Sarkis', 'Moghadam', 'Ba', 'Boutros', 'Nader', 'Gerges', 'Salib', 'Salib', 'Guirguis', 'Essa', 'Guirguis', 'Antoun', 'Kassis', 'Abboud', 'Najjar', 'Aswad', 'Srour', 'Mifsud', 'Ghanem', 'Bitar', 'Ghannam', 'Asghar', 'Deeb', 'Kalb', 'Nader', 'Srour', 'Attia', 'Shamon', 'Bata', 'Nahas', 'Gerges', 'Kanaan', 'Kassis', 'Sarkis', 'Maloof', 'Almasi', 'Nassar', 'Saliba', 'Arian', 'Ghanem', 'Awad', 'Naifeh', 'Boutros', 'Fakhoury', 'Sabbag', 'Antar', 'Tahan', 'Mustafa', 'Almasi', 'Shammas', 'Totah', 'Boutros', 'Cham', 'Shamon', 'Ganim', 'Ghanem', 'Assaf', 'Khoury', 'Naifeh', 'Bahar', 'Quraishi', 'Bishara', 'Cham', 'Asfour', 'Ghannam', 'Khoury', 'Sayegh', 'Hanania', 'Maroun', 'Kouri', 'Sarkis', 'Haik', 'Basara', 'Salib', 'Shammas', 'Fakhoury', 'Nahas', 'Ganim', 'Botros', 'Arian', 'Shalhoub', 'Hadad', 'Mustafa', 'Shalhoub', 'Kassab', 'Asker', 'Botros', 'Kanaan', 'Gaber', 'Bazzi', 'Sayegh', 'Nassar', 'Kassis', 'Fakhoury', 'Kassis', 'Amari', 'Sarraf', 'Mifsud', 'Salib', 'Samaha', 'Mustafa', 'Asfour', 'Najjar', 'Essa', 'Naifeh', 'Cham', 'Sarraf', 'Moghadam', 'Fakhoury', 'Assaf', 'Almasi', 'Asghar', 'Nader', 'Kalb', 'Shamoun', 'Gerges', 'Wasem', 'Morcos', 'Nader', 'Said', 'Safar', 'Quraishi', 'Samaha', 'Kassab', 'Deeb', 'Sarraf', 'Rahal', 'Naifeh', 'Ba', 'Nazari', 'Ganim', 'Arian', 'Asker', 'Touma', 'Kassab', 'Tahan', 'Mansour', 'Morcos', 'Shammas', 'Baba', 'Morcos', 'Isa', 'Moghadam', 'Ganem', 'Baz', 'Totah', 'Nader', 'Kouri', 'Guirguis', 'Koury', 'Zogby', 'Basara', 'Baz', 'Deeb', 'Mustafa', 'Shadid', 'Awad', 'Sarraf', 'Quraishi', 'Kanaan', 'Tahan', 'Ghannam', 'Shammas', 'Abboud', 'Najjar', 'Bishara', 'Tuma', 'Srour', 'Mifsud', 'Srour', 'Hajjar', 'Qureshi', 'Bitar', 'Hadad', 'Almasi', 'Wasem', 'Abadi', 'Maroun', 'Baz', 'Koury', 'Ganem', 'Awad', 'Maalouf', 'Mifsud', 'Haik', 'Sleiman', 'Arian', 'Seif', 'Mansour', 'Koury', 'Kattan', 'Koury', 'Aswad', 'Ba', 'Rahal', 'Zogby', 'Bahar', 'Fakhoury', 'Samaha', 'Sarraf', 'Mifsud', 'Antar', 'Moghadam', 'Botros', 'Srour', 'Sabbag', 'Sayegh', 'Rahal', 'Attia', 'Naifeh', 'Saliba', 'Mustafa', 'Amari', 'Issa', 'Masih', 'Khouri', 'Haddad', 'Kalb', 'Bazzi', 'Salib', 'Hanania', 'Shamoon', 'Tuma', 'Cham', 'Antoun', 'Wasem', 'Kouri', 'Ghanem', 'Wasem', 'Khoury', 'Assaf', 'Ganem', 'Seif', 'Nader', 'Essa', 'Shadid', 'Botros', 'Sleiman', 'Bishara', 'Basara', 'Maalouf', 'Issa', 'Nassar', 'Moghadam', 'Ganim', 'Kassis', 'Antoun', 'Said', 'Khouri', 'Salib', 'Baz', 'Sarkis', 'Tuma', 'Naifeh', 'Najjar', 'Asker', 'Khouri', 'Mustafa', 'Najjar', 'Sabbag', 'Malouf', 'Wasem', 'Maalouf', 'Gaber', 'Said', 'Zogby', 'Bahar', 'Hanania', 'Shalhoub', 'Abadi', 'Handal', 'Qureshi', 'Kanaan', 'Abboud', 'Mifsud', 'Touma', 'Ganim', 'Bishara', 'Bazzi', 'Gaber', 'Haik', 'Ghanem', 'Sarraf', 'Sarkis', 'Mustafa', 'Baz', 'Kanaan', 'Nazari', 'Bahar', 'Malouf', 'Quraishi', 'Kattan', 'Arian', 'Shadid', 'Tuma', 'Nader', 'Khoury', 'Safar', 'Wasem', 'Toma', 'Haddad', 'Quraishi', 'Nassar', 'Kanaan', 'Gaber', 'Haddad', 'Rahal', 'Koury', 'Harb', 'Mikhail', 'Dagher', 'Shadid', 'Boutros', 'Mikhail', 'Khouri', 'Nader', 'Issa', 'Harb', 'Dagher', 'Gerges', 'Morcos', 'Essa', 'Fakhoury', 'Tuma', 'Kattan', 'Totah', 'Qureshi', 'Nahas', 'Bitar', 'Tahan', 'Daher', 'Shammas', 'Kouri', 'Ganim', 'Daher', 'Awad', 'Malouf', 'Mustafa', 'Aswad']\n",
      "Chinese\n",
      "['Ang', 'AuYong', 'Bai', 'Ban', 'Bao', 'Bei', 'Bian', 'Bui', 'Cai', 'Cao', 'Cen', 'Chai', 'Chaim', 'Chan', 'Chang', 'Chao', 'Che', 'Chen', 'Cheng', 'Cheung', 'Chew', 'Chieu', 'Chin', 'Chong', 'Chou', 'Chu', 'Cui', 'Dai', 'Deng', 'Ding', 'Dong', 'Dou', 'Duan', 'Eng', 'Fan', 'Fei', 'Feng', 'Foong', 'Fung', 'Gan', 'Gauk', 'Geng', 'Gim', 'Gok', 'Gong', 'Guan', 'Guang', 'Guo', 'Gwock', 'Han', 'Hang', 'Hao', 'Hew', 'Hiu', 'Hong', 'Hor', 'Hsiao', 'Hua', 'Huan', 'Huang', 'Hui', 'Huie', 'Huo', 'Jia', 'Jiang', 'Jin', 'Jing', 'Joe', 'Kang', 'Kau', 'Khoo', 'Khu', 'Kong', 'Koo', 'Kwan', 'Kwei', 'Kwong', 'Lai', 'Lam', 'Lang', 'Lau', 'Law', 'Lew', 'Lian', 'Liao', 'Lim', 'Lin', 'Ling', 'Liu', 'Loh', 'Long', 'Loong', 'Luo', 'Mah', 'Mai', 'Mak', 'Mao', 'Mar', 'Mei', 'Meng', 'Miao', 'Min', 'Ming', 'Moy', 'Mui', 'Nie', 'Niu', 'OuYang', 'OwYang', 'Pan', 'Pang', 'Pei', 'Peng', 'Ping', 'Qian', 'Qin', 'Qiu', 'Quan', 'Que', 'Ran', 'Rao', 'Rong', 'Ruan', 'Sam', 'Seah', 'See ', 'Seow', 'Seto', 'Sha', 'Shan', 'Shang', 'Shao', 'Shaw', 'She', 'Shen', 'Sheng', 'Shi', 'Shu', 'Shuai', 'Shui', 'Shum', 'Siew', 'Siu', 'Song', 'Sum', 'Sun', 'Sze ', 'Tan', 'Tang', 'Tao', 'Teng', 'Teoh', 'Thean', 'Thian', 'Thien', 'Tian', 'Tong', 'Tow', 'Tsang', 'Tse', 'Tsen', 'Tso', 'Tze', 'Wan', 'Wang', 'Wei', 'Wen', 'Weng', 'Won', 'Wong', 'Woo', 'Xiang', 'Xiao', 'Xie', 'Xing', 'Xue', 'Xun', 'Yan', 'Yang', 'Yao', 'Yap', 'Yau', 'Yee', 'Yep', 'Yim', 'Yin', 'Ying', 'Yong', 'You', 'Yuan', 'Zang', 'Zeng', 'Zha', 'Zhan', 'Zhang', 'Zhao', 'Zhen', 'Zheng', 'Zhong', 'Zhou', 'Zhu', 'Zhuo', 'Zong', 'Zou', 'Bing', 'Chi', 'Chu', 'Cong', 'Cuan', 'Dan', 'Fei', 'Feng', 'Gai', 'Gao', 'Gou', 'Guan', 'Gui', 'Guo', 'Hong', 'Hou', 'Huan', 'Jian', 'Jiao', 'Jin', 'Jiu', 'Juan', 'Jue', 'Kan', 'Kuai', 'Kuang', 'Kui', 'Lao', 'Liang', 'Lu', 'Luo', 'Man', 'Nao', 'Pian', 'Qiao', 'Qing', 'Qiu', 'Rang', 'Rui', 'She', 'Shi', 'Shuo', 'Sui', 'Tai', 'Wan', 'Wei', 'Xian', 'Xie', 'Xin', 'Xing', 'Xiong', 'Xuan', 'Yan', 'Yin', 'Ying', 'Yuan', 'Yue', 'Yun', 'Zha', 'Zhai', 'Zhang', 'Zhi', 'Zhuan', 'Zhui']\n"
     ]
    }
   ],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "# Check that it worked\n",
    "\n",
    "for c in all_categories[:2]:\n",
    "    print(c)\n",
    "    print(category_lines[c]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-wallpaper",
   "metadata": {},
   "source": [
    "#### All countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "streaming-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese'])\n"
     ]
    }
   ],
   "source": [
    "print(category_lines.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-syndrome",
   "metadata": {},
   "source": [
    "#### Example: German names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "threaded-expression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbing', 'Abel', 'Abeln', 'Abt', 'Achilles']\n"
     ]
    }
   ],
   "source": [
    "print(category_lines['German'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-terrorist",
   "metadata": {},
   "source": [
    "### 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numeric-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n",
      "20074\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "targets = []\n",
    "\n",
    "for k,v in category_lines.items():\n",
    "    for name in v:\n",
    "        names.append(name)\n",
    "        targets.append(k)\n",
    "\n",
    "print(len(names))\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "common-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(names, targets, test_size = 0.2, random_state = 123, stratify = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "clear-dairy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the training data:  16059\n",
      "The number of observations in the test data:  4015\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of observations in the training data: \", len(X_train))\n",
    "print(\"The number of observations in the test data: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-component",
   "metadata": {},
   "source": [
    "### 3. Encode names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "banned-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create representation of the name\n",
    "def name_rep(name):\n",
    "    rep = torch.zeros(len(name), 1, n_letters) #Create a zeros tensor\n",
    "    #iterate through all the characters in the name\n",
    "    for index, letter in enumerate(name):\n",
    "        pos = all_letters.find(letter)\n",
    "        rep[index][0][pos] = 1 #Assign a value for each pos value\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "focused-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create vec representation of the language\n",
    "def lang_rep(lang):\n",
    "    return torch.tensor([all_categories.index(lang)], dtype = torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-student",
   "metadata": {},
   "source": [
    "#### Example of name and language representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "vocational-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0.]]])\n",
      "torch.Size([4, 1, 57])\n",
      "tensor([6])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#example of name representation\n",
    "beau = name_rep(\"beau\")\n",
    "print(beau)\n",
    "print(beau.shape)\n",
    "\n",
    "lang = lang_rep(\"German\")\n",
    "print(lang)\n",
    "print(lang.shape)\n",
    "# print(all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-tragedy",
   "metadata": {},
   "source": [
    "### 4. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "manufactured-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple rnn network \n",
    "import torch.nn as nn\n",
    "class RNN_net(nn.Module):\n",
    "    #Create a constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_net, self).__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        # Applies a multi-layer Elman RNN with \\tanhtanh or \\text{ReLU}ReLU non-linearity to an input sequence.\n",
    "        # nn.RNN()\n",
    "        self.rnn_cell = nn.RNN(input_size, hidden_size)\n",
    "        self.h20 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    #create a forward pass function\n",
    "    def forward(self, input_, hidden = None, batch_size = 1):\n",
    "        out, hidden = self.rnn_cell(input_, hidden)\n",
    "        output = self.h20(hidden.view(-1, self.hidden_size))\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size = 1):\n",
    "        #function to init the hidden layers\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-steam",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rising-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to run interference\n",
    "def infer(net, name, device = \"cpu\"):\n",
    "    name_ohe = name_rep(name).to(device)\n",
    "\n",
    "    #get the output\n",
    "    output, hidden = net(name_ohe)\n",
    "\n",
    "    if type(hidden) is tuple: #for lSTM\n",
    "        hidden = hidden[0]\n",
    "    index = torch.argmax(hidden)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "equal-trinity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of languages present:  18\n"
     ]
    }
   ],
   "source": [
    "#create hidden layers\n",
    "n_hidden = 128 #hidden layers count\n",
    "\n",
    "#number of languages\n",
    "n_languages = len(category_lines.keys())\n",
    "print(\"Total number of languages present: \", n_languages)\n",
    "\n",
    "#initialize the network\n",
    "net = RNN_net(input_size=n_letters, hidden_size=n_hidden, output_size=n_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fourth-preference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9477, -3.0273, -2.9186, -2.9304, -2.8071, -2.7905, -2.8676, -2.9192,\n",
       "         -3.0071, -2.7959, -2.8193, -2.8625, -2.9019, -2.8879, -3.0303, -2.8210,\n",
       "         -2.9022, -2.8388]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for inference\n",
    "net = net.to(device)\n",
    "infer(net, \"kumar\", device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "coordinated-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.9957, -2.9867, -2.9632, -2.9747, -2.8603, -2.9040, -2.8793, -2.8131,\n",
       "         -2.9525, -2.7328, -2.7486, -2.8436, -2.9248, -2.8446, -3.0442, -2.8433,\n",
       "         -2.9362, -2.8418]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = name_rep('A')\n",
    "\n",
    "# put stuff on GPU\n",
    "input = input.to(device)\n",
    "hidden = torch.zeros((1,1, n_hidden)).to(device)\n",
    "\n",
    "output, next_hidden = net(input, hidden)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "presidential-duplicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.9957, -2.9867, -2.9632, -2.9747, -2.8603, -2.9040, -2.8793, -2.8131,\n",
      "         -2.9525, -2.7328, -2.7486, -2.8436, -2.9248, -2.8446, -3.0442, -2.8433,\n",
      "         -2.9362, -2.8418]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-3.0031, -2.9854, -2.9370, -3.0118, -2.7898, -2.8088, -2.7997, -2.8483,\n",
      "         -2.9793, -2.7378, -2.8377, -2.8630, -2.9877, -2.9383, -3.0378, -2.7735,\n",
      "         -2.9251, -2.8382]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-2.9733, -3.0077, -2.9775, -2.9582, -2.8080, -2.7824, -2.7881, -2.8899,\n",
      "         -2.9802, -2.7620, -2.8139, -2.8748, -2.8930, -2.9887, -3.0873, -2.8493,\n",
      "         -2.8759, -2.7918]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-2.9643, -2.9691, -2.8957, -2.9035, -2.8444, -2.7950, -2.8628, -2.9064,\n",
      "         -3.0787, -2.7819, -2.8322, -2.8551, -2.9770, -2.9503, -3.0153, -2.8039,\n",
      "         -2.8929, -2.7608]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-2.9662, -3.0093, -2.9411, -2.9419, -2.8299, -2.8497, -2.8673, -2.8985,\n",
      "         -2.9658, -2.7566, -2.8161, -2.8556, -2.9006, -2.8603, -2.9987, -2.8271,\n",
      "         -2.9602, -2.8252]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[-2.9575, -3.0057, -2.9465, -2.9602, -2.8036, -2.7875, -2.8602, -2.9338,\n",
      "         -3.0264, -2.7572, -2.8098, -2.8025, -2.9254, -2.9394, -2.9843, -2.7983,\n",
      "         -2.9485, -2.8417]], device='cuda:1', grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = name_rep('Albert')\n",
    "hidden = torch.zeros((1,1, n_hidden))\n",
    "\n",
    "# put stuff on GPU\n",
    "input = input.to(device)\n",
    "hidden = hidden.to(device)\n",
    "\n",
    "next_hidden = hidden\n",
    "for i in range(input.shape[0]):\n",
    "    output, next_hidden = net(input[i].reshape(1,1,-1), next_hidden)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-friendship",
   "metadata": {},
   "source": [
    "### 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "statistical-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataloader\n",
    "# dataloader(2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "coordinated-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for l in all_categories: \n",
    "    count[l] = 0\n",
    "for k,v in category_lines.items():\n",
    "    count[k] += len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "progressive-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arabic': 2000, 'Chinese': 268, 'Czech': 519, 'Dutch': 297, 'English': 3668, 'French': 277, 'German': 724, 'Greek': 203, 'Irish': 232, 'Italian': 709, 'Japanese': 991, 'Korean': 94, 'Polish': 139, 'Portuguese': 74, 'Russian': 9408, 'Scottish': 100, 'Spanish': 298, 'Vietnamese': 73}\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baking-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd65e9c1eb8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt_ = sns.barplot(list(count.keys()), list(count.values()))\n",
    "plt_.set_xticklabels(plt_.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-heater",
   "metadata": {},
   "source": [
    "### 7. Dataloader & Evaluate Model\n",
    "\n",
    "Check whether it works before training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "honest-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(npoints, X_, y_):\n",
    "    \"\"\"Function to load the data\"\"\"\n",
    "    to_ret = []\n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_] #subset the data\n",
    "        to_ret.append((name, lang, name_rep(name), lang_rep(lang)))\n",
    "    \n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mineral-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Molina',\n",
       "  'Spanish',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([16])),\n",
       " ('Kerner',\n",
       "  'Czech',\n",
       "  tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "            0., 0., 0., 0., 0., 0.]]]),\n",
       "  tensor([2]))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataloader\n",
    "dataloader(2, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "biological-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, n_points, topk, X_, y_, device = \"cpu\"):\n",
    "    \"Evaluation function\"\n",
    "\n",
    "    net = net.eval().to(device)\n",
    "    data_ = dataloader(n_points, X_, y_)\n",
    "    correct = 0\n",
    "\n",
    "    #iterate\n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "\n",
    "        #get the output\n",
    "        output = infer(net, name, device)\n",
    "        val, indices = output.topk(topk) #get the top k values\n",
    "        indices = indices.to(device) #convert to devices\n",
    "        \n",
    "        if lang_rep in indices:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct/n_points\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "graduate-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.068"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the evaluation function\n",
    "eval(net, 1000, 1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-discussion",
   "metadata": {},
   "source": [
    "### 8. Batching pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "strategic-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a batched name rep\n",
    "\n",
    "def batched_name_rep(names, max_word_size):\n",
    "    rep = torch.zeros(max_word_size, len(names), n_letters)\n",
    "    for name_index, name in enumerate(names):\n",
    "        for letter_index, letter in enumerate(name):\n",
    "            pos = all_letters.find(letter)\n",
    "            rep[letter_index][name_index][pos] = 1\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dirty-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_char(name_reps):\n",
    "    name_reps = name_reps.view((-1, name_reps.size()[-1]))\n",
    "    for t in name_reps: \n",
    "        if torch.sum(t) == 0:\n",
    "            print('<pad>')\n",
    "        else:\n",
    "            index = t.argmax()\n",
    "            print(all_letters[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "published-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_lang_rep(langs):\n",
    "    rep = torch.zeros([len(langs)], dtype=torch.long)\n",
    "    for index, lang in enumerate(langs):\n",
    "        rep[index] = all_categories.index(lang)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "architectural-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "def batched_dataloader(npoints, X_, y_, verbose=False, device = 'cpu'):\n",
    "    names = []\n",
    "    langs = []\n",
    "    X_lengths = []\n",
    "    \n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_]\n",
    "        X_lengths.append(len(name))\n",
    "        names.append(name)\n",
    "        langs.append(lang)\n",
    "    max_length = max(X_lengths)\n",
    "    \n",
    "    names_rep = batched_name_rep(names, max_length).to(device)\n",
    "    langs_rep = batched_lang_rep(langs).to(device)\n",
    "    \n",
    "    padded_names_rep = torch.nn.utils.rnn.pack_padded_sequence(names_rep, X_lengths, enforce_sorted = False)\n",
    "    \n",
    "    if verbose:\n",
    "        print(names_rep.shape, padded_names_rep.data.shape)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print(names)\n",
    "        print_char(names_rep)\n",
    "        print('--')\n",
    "    \n",
    "    if verbose:\n",
    "        print_char(padded_names_rep.data)\n",
    "        print('Lang Rep', langs_rep.data)\n",
    "        print('Batch sizes', padded_names_rep.batch_sizes)\n",
    "    \n",
    "    \n",
    "    return padded_names_rep.to(device), langs_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "human-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "I\n",
      "e\n",
      "v\n",
      "a\n",
      "o\n",
      "u\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n"
     ]
    }
   ],
   "source": [
    "out_ = batched_name_rep(['Beau', 'Ivo'], 5)\n",
    "print_char(out_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "minor-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 2, 57]) torch.Size([14, 57])\n",
      "--\n",
      "['Atlanov', 'Egleton']\n",
      "A\n",
      "E\n",
      "t\n",
      "g\n",
      "l\n",
      "l\n",
      "a\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "o\n",
      "v\n",
      "n\n",
      "--\n",
      "A\n",
      "E\n",
      "t\n",
      "g\n",
      "l\n",
      "l\n",
      "a\n",
      "e\n",
      "n\n",
      "t\n",
      "o\n",
      "o\n",
      "v\n",
      "n\n",
      "Lang Rep tensor([14,  4])\n",
      "Batch sizes tensor([2, 2, 2, 2, 2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0.]]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 2]), sorted_indices=tensor([0, 1]), unsorted_indices=tensor([0, 1])),\n",
       " tensor([14,  4]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataloader(2, X_train, y_train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-coral",
   "metadata": {},
   "source": [
    "### 10. Training\n",
    "#### 10.1 Define train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adaptive-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, opt, criterion, n_points):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    total_loss = 0\n",
    "    \n",
    "    data_ = dataloader(n_points, X_train, y_train)\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "\n",
    "        hidden = net.init_hidden()\n",
    "\n",
    "        for i in range(name_ohe.size()[0]):\n",
    "            output, hidden = net(name_ohe[i:i+1], hidden)\n",
    "            \n",
    "        loss = criterion(output, lang_rep)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    opt.step()       \n",
    "    return total_loss/n_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "swiss-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, n_points, device = 'cpu'):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    batch_input, batch_groundtruth = batched_dataloader(n_points, X_train, y_train, False, device)\n",
    "    \n",
    "    output, hidden = net(batch_input)\n",
    "    \n",
    "    loss = criterion(output, batch_groundtruth)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-atlantic",
   "metadata": {},
   "source": [
    "#### 10.2 Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "technological-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RNN_net(n_letters, n_hidden, n_categories)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-module",
   "metadata": {},
   "source": [
    "#### 10.4 Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "lovely-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 s, sys: 503 ms, total: 7.16 s\n",
      "Wall time: 1.68 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8584, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "#time for normal training\n",
    "train(net, opt, criterion, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-brake",
   "metadata": {},
   "source": [
    "### 11. Full training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "desperate-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            # print('Top-1:', eval(net, len(X_test), 1, X_test, y_test), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test))\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    print('Top-1 Accuracy:', eval(net, len(X_test), 1, X_test, y_test, device), 'Top-2 Accuracy:', eval(net, len(X_test), 2, X_test, y_test, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "based-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2999 Loss 0.5385945439338684\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd65ea1bf60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Top-1 Accuracy: 0.7599003735990038 Top-2 Accuracy: 0.862266500622665\n",
      "CPU times: user 33min 58s, sys: 49.4 s, total: 34min 47s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#training RNN using batch technique\n",
    "net = RNN_net(n_letters, 128, n_languages)\n",
    "train_setup(net, lr=0.15, n_batches=3200, batch_size = 512, display_freq=500) # CPU Training example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
