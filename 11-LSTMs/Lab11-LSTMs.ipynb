{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 11: Long Short Term Memory (LSTM) Models\n",
    "#### Pranisaa Charnparttaravanit\n",
    "#### st121720\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for this lab is to find a dataset and evaluate it with the code developed in class. The chosen data set is called MultiWOZ_2.2 taken from th elinke attached below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Get data provided by Github \n",
    "Link https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-08 13:44:29--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_001.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10678768 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_001.json’\n",
      "\n",
      "dialogues_001.json  100%[===================>]  10.18M  7.99MB/s    in 1.3s    \n",
      "\n",
      "2021-04-08 13:44:31 (7.99 MB/s) - ‘dialogues_001.json’ saved [10678768/10678768]\n",
      "\n",
      "--2021-04-08 13:44:32--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_002.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10779713 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_002.json’\n",
      "\n",
      "dialogues_002.json  100%[===================>]  10.28M  9.50MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:44:33 (9.50 MB/s) - ‘dialogues_002.json’ saved [10779713/10779713]\n",
      "\n",
      "--2021-04-08 13:44:35--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_003.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 9980098 (9.5M) [text/plain]\n",
      "Saving to: ‘dialogues_003.json’\n",
      "\n",
      "dialogues_003.json  100%[===================>]   9.52M  9.23MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:44:36 (9.23 MB/s) - ‘dialogues_003.json’ saved [9980098/9980098]\n",
      "\n",
      "--2021-04-08 13:44:38--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_004.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10267341 (9.8M) [text/plain]\n",
      "Saving to: ‘dialogues_004.json’\n",
      "\n",
      "dialogues_004.json  100%[===================>]   9.79M  9.36MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:44:39 (9.36 MB/s) - ‘dialogues_004.json’ saved [10267341/10267341]\n",
      "\n",
      "--2021-04-08 13:44:41--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_005.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10518980 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_005.json’\n",
      "\n",
      "dialogues_005.json  100%[===================>]  10.03M  9.34MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:44:42 (9.34 MB/s) - ‘dialogues_005.json’ saved [10518980/10518980]\n",
      "\n",
      "--2021-04-08 13:44:44--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_006.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10567400 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_006.json’\n",
      "\n",
      "dialogues_006.json  100%[===================>]  10.08M  9.55MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:44:45 (9.55 MB/s) - ‘dialogues_006.json’ saved [10567400/10567400]\n",
      "\n",
      "--2021-04-08 13:44:47--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_007.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10362425 (9.9M) [text/plain]\n",
      "Saving to: ‘dialogues_007.json’\n",
      "\n",
      "dialogues_007.json  100%[===================>]   9.88M  9.53MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:44:48 (9.53 MB/s) - ‘dialogues_007.json’ saved [10362425/10362425]\n",
      "\n",
      "--2021-04-08 13:44:50--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_008.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10207271 (9.7M) [text/plain]\n",
      "Saving to: ‘dialogues_008.json’\n",
      "\n",
      "dialogues_008.json  100%[===================>]   9.73M  9.37MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:44:51 (9.37 MB/s) - ‘dialogues_008.json’ saved [10207271/10207271]\n",
      "\n",
      "--2021-04-08 13:44:53--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_009.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10168917 (9.7M) [text/plain]\n",
      "Saving to: ‘dialogues_009.json’\n",
      "\n",
      "dialogues_009.json  100%[===================>]   9.70M  9.29MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:44:54 (9.29 MB/s) - ‘dialogues_009.json’ saved [10168917/10168917]\n",
      "\n",
      "--2021-04-08 13:44:55--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_010.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10539061 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_010.json’\n",
      "\n",
      "dialogues_010.json  100%[===================>]  10.05M  9.36MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:44:57 (9.36 MB/s) - ‘dialogues_010.json’ saved [10539061/10539061]\n",
      "\n",
      "--2021-04-08 13:44:58--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_011.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10326640 (9.8M) [text/plain]\n",
      "Saving to: ‘dialogues_011.json’\n",
      "\n",
      "dialogues_011.json  100%[===================>]   9.85M  9.33MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:45:00 (9.33 MB/s) - ‘dialogues_011.json’ saved [10326640/10326640]\n",
      "\n",
      "--2021-04-08 13:45:01--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_012.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10584880 (10M) [text/plain]\n",
      "Saving to: ‘dialogues_012.json’\n",
      "\n",
      "dialogues_012.json  100%[===================>]  10.09M  9.58MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:45:03 (9.58 MB/s) - ‘dialogues_012.json’ saved [10584880/10584880]\n",
      "\n",
      "--2021-04-08 13:45:04--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_013.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10471034 (10.0M) [text/plain]\n",
      "Saving to: ‘dialogues_013.json’\n",
      "\n",
      "dialogues_013.json  100%[===================>]   9.99M  9.48MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:45:05 (9.48 MB/s) - ‘dialogues_013.json’ saved [10471034/10471034]\n",
      "\n",
      "--2021-04-08 13:45:07--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_014.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10260484 (9.8M) [text/plain]\n",
      "Saving to: ‘dialogues_014.json’\n",
      "\n",
      "dialogues_014.json  100%[===================>]   9.79M  9.31MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:45:08 (9.31 MB/s) - ‘dialogues_014.json’ saved [10260484/10260484]\n",
      "\n",
      "--2021-04-08 13:45:10--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_015.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10423185 (9.9M) [text/plain]\n",
      "Saving to: ‘dialogues_015.json.1’\n",
      "\n",
      "dialogues_015.json. 100%[===================>]   9.94M  9.46MB/s    in 1.1s    \n",
      "\n",
      "2021-04-08 13:45:11 (9.46 MB/s) - ‘dialogues_015.json.1’ saved [10423185/10423185]\n",
      "\n",
      "--2021-04-08 13:45:13--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_016.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 10218682 (9.7M) [text/plain]\n",
      "Saving to: ‘dialogues_016.json.1’\n",
      "\n",
      "dialogues_016.json. 100%[===================>]   9.75M  9.49MB/s    in 1.0s    \n",
      "\n",
      "2021-04-08 13:45:14 (9.49 MB/s) - ‘dialogues_016.json.1’ saved [10218682/10218682]\n",
      "\n",
      "--2021-04-08 13:45:16--  https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_017.json\n",
      "Connecting to 192.41.170.23:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 5020445 (4.8M) [text/plain]\n",
      "Saving to: ‘dialogues_017.json.1’\n",
      "\n",
      "dialogues_017.json. 100%[===================>]   4.79M  8.04MB/s    in 0.6s    \n",
      "\n",
      "2021-04-08 13:45:17 (8.04 MB/s) - ‘dialogues_017.json.1’ saved [5020445/5020445]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['001','002','003','004','005','006','007','008','009','010','011','012','013','014','015','016','017']:\n",
    "    !wget 'https://raw.githubusercontent.com/budzianowski/multiwoz/master/data/MultiWOZ_2.2/train/dialogues_{i}.json'\n",
    "    !mv 'dialogues_{i}.json' 'data/multiwoz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "  \n",
    "for i in ['001','002','003','004','005','006','007','008','009','010','011','012','013','014','015','016','017']:\n",
    "    if i =='001':\n",
    "        f = open(f'data/multiwoz/dialogues_{i}.json')\n",
    "        data = json.load(f)\n",
    "        all_question, all_answer = [], []\n",
    "\n",
    "        for qa in data:\n",
    "            all_question.append(qa[u'turns'][0][u'utterance'])\n",
    "            all_answer.append(qa[u'turns'][1][u'utterance'])\n",
    "\n",
    "        all_0 = pd.DataFrame([all_question,all_answer]).T\n",
    "\n",
    "    else : \n",
    "        f = open(f'data/multiwoz/dialogues_{i}.json')\n",
    "        data = json.load(f)\n",
    "        all_question, all_answer = [], []\n",
    "\n",
    "        for qa in data:\n",
    "            all_question.append(qa[u'turns'][0][u'utterance'])\n",
    "            all_answer.append(qa[u'turns'][1][u'utterance'])\n",
    "\n",
    "        all_1 = pd.DataFrame([all_question,all_answer]).T\n",
    "\n",
    "        all = pd.concat([all_0, all_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i need a place to dine in the center thats exp...</td>\n",
       "      <td>I have several options for you; do you prefer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guten Tag, I am staying overnight in Cambridge...</td>\n",
       "      <td>I have 4 different options for you. I have two...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi there! Can you give me some info on Cityroomz?</td>\n",
       "      <td>Cityroomz is located at Sleeperz Hotel, Statio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am looking for a hotel named alyesbray lodge...</td>\n",
       "      <td>i have their info, what would you like to know?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i need a train on tuesday out of kings lynn</td>\n",
       "      <td>What time of day would you like to leave?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>I would like to visit some of the architecture...</td>\n",
       "      <td>I can indeed. We have several churches and a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Hi, can you help me find a moderately priced 3...</td>\n",
       "      <td>I have 4 guesthouses with 3 stars that are mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Hi! I am looking for a train that arrives by 1...</td>\n",
       "      <td>I have 122 trains that are arriving by 11:30. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>I would like the phone number of an expensive ...</td>\n",
       "      <td>There are five restaurants in the expensive pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Hello, I am looking for a cheap restaurant tha...</td>\n",
       "      <td>It looks like there are no German restaurants ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8437 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  \\\n",
       "0    i need a place to dine in the center thats exp...   \n",
       "1    Guten Tag, I am staying overnight in Cambridge...   \n",
       "2    Hi there! Can you give me some info on Cityroomz?   \n",
       "3    I am looking for a hotel named alyesbray lodge...   \n",
       "4          i need a train on tuesday out of kings lynn   \n",
       "..                                                 ...   \n",
       "241  I would like to visit some of the architecture...   \n",
       "242  Hi, can you help me find a moderately priced 3...   \n",
       "243  Hi! I am looking for a train that arrives by 1...   \n",
       "244  I would like the phone number of an expensive ...   \n",
       "245  Hello, I am looking for a cheap restaurant tha...   \n",
       "\n",
       "                                                     1  \n",
       "0    I have several options for you; do you prefer ...  \n",
       "1    I have 4 different options for you. I have two...  \n",
       "2    Cityroomz is located at Sleeperz Hotel, Statio...  \n",
       "3      i have their info, what would you like to know?  \n",
       "4            What time of day would you like to leave?  \n",
       "..                                                 ...  \n",
       "241  I can indeed. We have several churches and a s...  \n",
       "242  I have 4 guesthouses with 3 stars that are mod...  \n",
       "243  I have 122 trains that are arriving by 11:30. ...  \n",
       "244  There are five restaurants in the expensive pr...  \n",
       "245  It looks like there are no German restaurants ...  \n",
       "\n",
       "[8437 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Save as txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.savetxt(r'data/qa/multiwoz_all.txt', all_.values, fmt='%s', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class NaiveCustomLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        \n",
    "        # Parameters for computing i_t\n",
    "        self.U_i = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_i = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing f_t\n",
    "        self.U_f = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_f = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing c_t\n",
    "        self.U_c = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_c = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_c = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        # Parameters for computing o_t\n",
    "        self.U_o = nn.Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.V_o = nn.Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = nn.Parameter(torch.Tensor(hidden_sz))\n",
    "        \n",
    "        self.init_weights()\n",
    "                \n",
    "    def init_weights(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "         \n",
    "    def forward(self, x, init_states=None):\n",
    "        \"\"\"\n",
    "        forward: Run input x through the cell. Assumes x.shape is (batch_size, sequence_length, input_size)\n",
    "        \"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        \n",
    "        if init_states is None:\n",
    "            h_t, c_t = (\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "                torch.zeros(bs, self.hidden_size).to(x.device),\n",
    "            )\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "            \n",
    "        for t in range(seq_sz):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            i_t = torch.sigmoid(x_t @ self.U_i + h_t @ self.V_i + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.U_f + h_t @ self.V_f + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.U_c + h_t @ self.V_c + self.b_c)\n",
    "            o_t = torch.sigmoid(x_t @ self.U_o + h_t @ self.V_o + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            \n",
    "            hidden_seq.append(h_t.unsqueeze(0))\n",
    "        \n",
    "        # Reshape hidden_seq tensor to (batch size, sequence length, hidden_size)\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
    "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
    "\n",
    "        return hidden_seq, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check availability of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured device:  cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from chosen_gpu import get_freer_gpu\n",
    "device = torch.device(get_freer_gpu()) \n",
    "print(\"Configured device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserved word tokens\n",
    "\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "\n",
    "    def __init__(self):        \n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index: # add new index for new word\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1 # set count\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1 #update uniqiue word\n",
    "        else:\n",
    "            self.word2count[word] += 1 # count\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30  # Maximum sentence length to consider\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# Read query/response pairs and return a Voc object\n",
    "\n",
    "def readVocs(datafile):\n",
    "    print(\"Reading lines...\")    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc()\n",
    "    return voc, pairs\n",
    "\n",
    "# Boolean function returning True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using the filterPair predicate\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "\n",
    "def loadPrepareData(datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 8437 sentence pairs\n",
      "Trimmed to 7913 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 2439\n",
      "\n",
      "pairs:\n",
      "['i need a place to dine in the center thats expensive', 'i have several options for you do you prefer african asian or british food ?']\n",
      "['guten tag i am staying overnight in cambridge and need a place to sleep . i need free parking and internet .', 'i have different options for you . i have two cheaper guesthouses and two expensive hotels . do you have a preference ?']\n",
      "['i am looking for a hotel named alyesbray lodge guest house .', 'i have their info what would you like to know ?']\n",
      "['i need a train on tuesday out of kings lynn', 'what time of day would you like to leave ?']\n",
      "['i am looking for a restaurant . i would like something cheap that has chinese food .', 'i ve heard good things about the lucky star . need a reservation ?']\n",
      "['please find me a train from cambridge to stansted airport', 'sure i can do that but first i need a little more information . what day would you like to travel as well as departure and arrival times ?']\n",
      "['i m looking for an expensive restaurant in the centre if you could help me .', 'i sure can . there are lots of choices . are you looking for a particular type of food ?']\n",
      "['i m looking for a places to go and see during my upcoming trip to cambridge .', 'what area of town would you like ?']\n",
      "['hi i d like to book a train to stansted airport from cambridge . can you help ?', 'absolutely . where will you departing from ?']\n",
      "['yeah could you recommend a good gastropub ?', 'backstreet bistro . it s expensive though . there is a moderately priced one called the cow pizza kitchen and bar if preferred .']\n"
     ]
    }
   ],
   "source": [
    "datafile = 'data/qa/multiwoz_all.txt'\n",
    "voc, pairs = loadPrepareData(datafile)\n",
    "\n",
    "# Print some pairs to validate\n",
    "\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 1393 / 2436 = 0.5718\n",
      "Trimmed from 7913 pairs to 6903, 0.8724 of total\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "# Trim vocabulary and pairs\n",
    "\n",
    "pairs_ = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split dataset into testing and training pair sets\n",
    "\n",
    "Let's split the dataset into the first 45,000 pairs for training and the rest for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7913\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))\n",
    "testpairs = pairs_[6000:]\n",
    "pairs  = pairs_[:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6903\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Convert pairs to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Return a padded input sequence tensor and the lengths of each original sequence\n",
    "\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Return a padded target sequence tensor, a padding mask, and the max target length\n",
    "\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Return all items for a given batch of pairs\n",
    "\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "# Example for validation\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LSTM takes time series data so we need to convert our pairs of sentences into time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i need a place to dine in the center thats expensive', 'i have several options for you do you prefer african asian or british food ?'], ['i need a train on tuesday out of kings lynn', 'what time of day would you like to leave ?'], ['i am looking for a restaurant . i would like something cheap that has chinese food .', 'i ve heard good things about the lucky star . need a reservation ?'], ['please find me a train from cambridge to stansted airport', 'sure i can do that but first i need a little more information . what day would you like to travel as well as departure and arrival times ?'], ['i m looking for an expensive restaurant in the centre if you could help me .', 'i sure can . there are lots of choices . are you looking for a particular type of food ?']]\n",
      "====================\n",
      "[['i am looking for a restaurant . i would like something cheap that has chinese food .', 'i ve heard good things about the lucky star . need a reservation ?'], ['i m looking for an expensive restaurant in the centre if you could help me .', 'i sure can . there are lots of choices . are you looking for a particular type of food ?'], ['i need a place to dine in the center thats expensive', 'i have several options for you do you prefer african asian or british food ?'], ['i need a train on tuesday out of kings lynn', 'what time of day would you like to leave ?'], ['please find me a train from cambridge to stansted airport', 'sure i can do that but first i need a little more information . what day would you like to travel as well as departure and arrival times ?']]\n",
      "====================\n",
      "tensor([[   3,  382,  528,    3,   67],\n",
      "        [1147,  103,  133,   14,  131],\n",
      "        [ 276,  104,    5,  418,    5],\n",
      "        [  79,  197,  421,  109,  848],\n",
      "        [ 249,   85,   64,    7,  651],\n",
      "        [ 857,    3,    9,  186,  177],\n",
      "        [ 219,  260,  216,   32,   64],\n",
      "        [ 278,   10,   32,  133,   55],\n",
      "        [ 406,  116,  133,  103,   10],\n",
      "        [  32,   30,  356,    5,  240],\n",
      "        [   2,  170,  409,  490,  231],\n",
      "        [   0,  171,   26,  170,   58],\n",
      "        [   0,   18,    2,  619,  117],\n",
      "        [   0,  104,    0,   18,   32],\n",
      "        [   0,   42,    0,   51,   51],\n",
      "        [   0,   17,    0,   52,   18],\n",
      "        [   0,    9,    0,    7,   52],\n",
      "        [   0,   10,    0,  186,   10],\n",
      "        [   0,   43,    0,    9,  148],\n",
      "        [   0,   26,    0,   23,  149],\n",
      "        [   0,    2,    0,   19,   23],\n",
      "        [   0,    0,    0,   18,    5],\n",
      "        [   0,    0,    0,    4,   77],\n",
      "        [   0,    0,    0,   34,   26],\n",
      "        [   0,    0,    0,   30,    2],\n",
      "        [   0,    0,    0,   23,    0],\n",
      "        [   0,    0,    0,  187,    0],\n",
      "        [   0,    0,    0,   26,    0],\n",
      "        [   0,    0,    0,    2,    0]])\n",
      "====================\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0]], dtype=torch.uint8)\n",
      "====================\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "pair_batch = pairs[:5]\n",
    "print(pair_batch)\n",
    "pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "print('='*20)\n",
    "print(pair_batch)\n",
    "print('='*20)\n",
    "print(target_variable)\n",
    "print('='*20)\n",
    "print(mask)\n",
    "print('='*20)\n",
    "print(max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        \n",
    "        embedded = self.embedding(input_seq)\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths.cpu())\n",
    "        \n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        \n",
    "        return outputs, hidden\n",
    "    def init_hidden(self):\n",
    "        \n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "       \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))#, bidirectional=True)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1 Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "        attn_energies = attn_energies.t()\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "  \n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    \n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    \n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    \n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            \n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            \n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Full training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " max_target_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    losslist = []\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        \n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        \n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        \n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "            losslist.append(print_loss_avg)\n",
    "        \n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            print(directory)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'check:qpoint')))\n",
    "    return losslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluation function\n",
    "#### 9.1 **Greedy decoding**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        \n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        \n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "       \n",
    "        for _ in range(max_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            \n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        \n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.2 Evaluating some text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "  \n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    \n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    \n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    \n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    \n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    \n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            \n",
    "            input_sentence = input('> ')\n",
    "            \n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            \n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            \n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            \n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.3 Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 4\n",
    "dropout = 0.5\n",
    "batch_size = 256 \n",
    "loadFilename = None\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 250; Percent complete: 2.5%; Average loss: 4.5527\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 500; Percent complete: 5.0%; Average loss: 3.1545\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 750; Percent complete: 7.5%; Average loss: 2.3426\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 1000; Percent complete: 10.0%; Average loss: 1.9632\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 1250; Percent complete: 12.5%; Average loss: 1.7084\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 1500; Percent complete: 15.0%; Average loss: 1.4828\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 1750; Percent complete: 17.5%; Average loss: 1.2811\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 2000; Percent complete: 20.0%; Average loss: 1.0775\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 2250; Percent complete: 22.5%; Average loss: 0.8881\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 2500; Percent complete: 25.0%; Average loss: 0.7185\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 2750; Percent complete: 27.5%; Average loss: 0.5625\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 3000; Percent complete: 30.0%; Average loss: 0.4322\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 3250; Percent complete: 32.5%; Average loss: 0.3336\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 3500; Percent complete: 35.0%; Average loss: 0.2523\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 3750; Percent complete: 37.5%; Average loss: 0.1963\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 4000; Percent complete: 40.0%; Average loss: 0.1567\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 4250; Percent complete: 42.5%; Average loss: 0.1324\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 4500; Percent complete: 45.0%; Average loss: 0.1085\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 4750; Percent complete: 47.5%; Average loss: 0.0925\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 5000; Percent complete: 50.0%; Average loss: 0.0809\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 5250; Percent complete: 52.5%; Average loss: 0.0699\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 5500; Percent complete: 55.0%; Average loss: 0.0606\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 5750; Percent complete: 57.5%; Average loss: 0.0555\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 6000; Percent complete: 60.0%; Average loss: 0.0487\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 6250; Percent complete: 62.5%; Average loss: 0.0548\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 6500; Percent complete: 65.0%; Average loss: 0.0444\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 6750; Percent complete: 67.5%; Average loss: 0.0386\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 7000; Percent complete: 70.0%; Average loss: 0.0372\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 7250; Percent complete: 72.5%; Average loss: 0.0339\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 7500; Percent complete: 75.0%; Average loss: 0.0356\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 7750; Percent complete: 77.5%; Average loss: 0.0282\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 8000; Percent complete: 80.0%; Average loss: 0.0306\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 8250; Percent complete: 82.5%; Average loss: 0.0333\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 8500; Percent complete: 85.0%; Average loss: 0.0347\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 8750; Percent complete: 87.5%; Average loss: 0.0307\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 9000; Percent complete: 90.0%; Average loss: 0.0276\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 9250; Percent complete: 92.5%; Average loss: 0.0270\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 9500; Percent complete: 95.0%; Average loss: 0.0244\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 9750; Percent complete: 97.5%; Average loss: 0.0213\n",
      "content/cb_model/Chat/2-4_512\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 10000; Percent complete: 100.0%; Average loss: 0.0272\n",
      "content/cb_model/Chat/2-4_512\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'content/'\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 10000\n",
    "print_every = 250\n",
    "save_every = 100\n",
    "loadFilename = None\n",
    "corpus_name=\"Chat\"\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "print(\"Starting Training!\")\n",
    "lossvalues = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.4 Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f950085fd30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lossvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.5 Bleu score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2857142857142857 0.032530002431617765\n",
      "Total Bleu Score for 1 grams on testing pairs:  0.25196698706007564\n",
      "Total Bleu Score for 2 grams on testing pairs:  0.13918339745773478\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "gram1_bleu_score = []\n",
    "gram2_bleu_score = []\n",
    "# print(len(testpairs))\n",
    "for i in range(0,len(testpairs),1):\n",
    "    input_sentence = testpairs[i][0]\n",
    "  \n",
    "    reference = testpairs[i][1:]\n",
    "    templist = []\n",
    "    for k in range(len(reference)):\n",
    "        if(reference[k]!=''):\n",
    "            temp = reference[k].split(' ')\n",
    "            templist.append(temp)\n",
    "  \n",
    "  \n",
    "    input_sentence = normalizeString(input_sentence)\n",
    "    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "    chencherry = SmoothingFunction()\n",
    "#   print(output_words)\n",
    "#   print(templist)\n",
    "    score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\n",
    "    score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \n",
    "    gram1_bleu_score.append(score1)\n",
    "    gram2_bleu_score.append(score2)\n",
    "    if i%1000 == 0:\n",
    "        print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\n",
    "print(\"Total Bleu Score for 1 grams on testing pairs: \", sum(gram1_bleu_score)/len(gram1_bleu_score) )  \n",
    "print(\"Total Bleu Score for 2 grams on testing pairs: \", sum(gram2_bleu_score)/len(gram2_bleu_score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: do you want to start in a particular area ? also also need them . is cheap .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  how much?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i have no results for entertainments . would you like to find it down ? is there a certain part of town you d like to find ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  which city?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: what type of food would you like ? are you interested in a certain area ? is an certain number . are also an king number .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  pizza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: what type of food would you like ? is available . is in the centre . has free parking . . has free\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ed6594a68986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Begin chatting (uncomment and run the following line to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Hi, how are you?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-ec18c2cf8348>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)\n",
    "# input\n",
    "# Hi, how are you?\n",
    "# What\n",
    "# I don't understand you\n",
    "# hmm, good bye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Beam Decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, decoder_hidden, last_idx=SOS_token, sentence_idxes=[], sentence_scores=[]):\n",
    "        if(len(sentence_idxes) != len(sentence_scores)):\n",
    "            raise ValueError(\"length of indexes and scores should be the same\")\n",
    "        self.decoder_hidden = decoder_hidden\n",
    "        self.last_idx = last_idx\n",
    "        self.sentence_idxes =  sentence_idxes\n",
    "        self.sentence_scores = sentence_scores\n",
    "\n",
    "    def avgScore(self):\n",
    "        if len(self.sentence_scores) == 0:\n",
    "            raise ValueError(\"Calculate average score of sentence, but got no word\")\n",
    "        # return mean of sentence_score\n",
    "        return sum(self.sentence_scores) / len(self.sentence_scores)\n",
    "\n",
    "    def addTopk(self, topi, topv, decoder_hidden, beam_size, voc):\n",
    "        topv = torch.log(topv)\n",
    "        terminates, sentences = [], []\n",
    "        for i in range(beam_size):\n",
    "            if topi[0][i] == EOS_token:\n",
    "                terminates.append(([voc.index2word[idx.item()] for idx in self.sentence_idxes] + ['<EOS>'],\n",
    "                                   self.avgScore())) \n",
    "                continue\n",
    "            idxes = self.sentence_idxes[:] \n",
    "            scores = self.sentence_scores[:] \n",
    "            idxes.append(topi[0][i])\n",
    "            scores.append(topv[0][i])\n",
    "            sentences.append(Sentence(decoder_hidden, topi[0][i], idxes, scores))\n",
    "        return terminates, sentences\n",
    "\n",
    "    def toWordScore(self, voc):\n",
    "        \n",
    "        words = []\n",
    "        for i in range(len(self.sentence_idxes)):\n",
    "            if self.sentence_idxes[i] == EOS_token:\n",
    "                words.append('<EOS>')\n",
    "            else:\n",
    "                words.append(voc.index2word[self.sentence_idxes[i].item()])\n",
    "       \n",
    "        if self.sentence_idxes[-1] != EOS_token:\n",
    "            words.append('<EOS>')\n",
    "        return (words, self.avgScore())\n",
    "\n",
    "    def __repr__(self):\n",
    "        res = f\"Sentence with indices {self.sentence_idxes} \"\n",
    "        res += f\"and scores {self.sentence_scores}\"\n",
    "        return res\n",
    "def beam_decode(decoder, decoder_hidden, encoder_outputs, voc, beam_size, max_length=MAX_LENGTH):\n",
    "    terminal_sentences, prev_top_sentences, next_top_sentences = [], [], []\n",
    "    prev_top_sentences.append(Sentence(decoder_hidden))\n",
    "    for i in range(max_length):\n",
    "        \n",
    "        for sentence in prev_top_sentences:\n",
    "            decoder_input = torch.LongTensor([[sentence.last_idx]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "\n",
    "            decoder_hidden = sentence.decoder_hidden\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(beam_size)\n",
    "            term, top = sentence.addTopk(topi, topv, decoder_hidden, beam_size, voc)\n",
    "            terminal_sentences.extend(term)\n",
    "            next_top_sentences.extend(top)\n",
    "           \n",
    "        \n",
    "        next_top_sentences.sort(key=lambda s: s.avgScore(), reverse=True)\n",
    "        prev_top_sentences = next_top_sentences[:beam_size]\n",
    "        next_top_sentences = []\n",
    "        \n",
    "\n",
    "    terminal_sentences += [sentence.toWordScore(voc) for sentence in prev_top_sentences]\n",
    "    terminal_sentences.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    n = min(len(terminal_sentences), 15)\n",
    "    return terminal_sentences[:n]\n",
    "\n",
    "\n",
    "\n",
    "class BeamSearchDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, voc, beam_size=10):\n",
    "        super(BeamSearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.voc = voc\n",
    "        self.beam_size = beam_size\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n",
    "        \n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        sentences = beam_decode(self.decoder, decoder_hidden, encoder_outputs, self.voc, self.beam_size, max_length)\n",
    "        \n",
    "        \n",
    "        all_tokens = [torch.tensor(self.voc.word2index.get(w, 0)) for w in sentences[0][0]]\n",
    "        return all_tokens, None\n",
    "\n",
    "    def __str__(self):\n",
    "        res = f\"BeamSearchDecoder with beam size {self.beam_size}\"\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.1 Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 4\n",
    "dropout = 0.5\n",
    "batch_size = 256 \n",
    "loadFilename = None\n",
    "\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 250; Percent complete: 4.2%; Average loss: 4.5309\n",
      "Iteration: 500; Percent complete: 8.3%; Average loss: 3.1358\n",
      "Iteration: 750; Percent complete: 12.5%; Average loss: 2.3069\n",
      "Iteration: 1000; Percent complete: 16.7%; Average loss: 1.9182\n",
      "Iteration: 1250; Percent complete: 20.8%; Average loss: 1.6442\n",
      "Iteration: 1500; Percent complete: 25.0%; Average loss: 1.4022\n",
      "Iteration: 1750; Percent complete: 29.2%; Average loss: 1.1859\n",
      "Iteration: 2000; Percent complete: 33.3%; Average loss: 0.9709\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 2250; Percent complete: 37.5%; Average loss: 0.7857\n",
      "Iteration: 2500; Percent complete: 41.7%; Average loss: 0.6115\n",
      "Iteration: 2750; Percent complete: 45.8%; Average loss: 0.4670\n",
      "Iteration: 3000; Percent complete: 50.0%; Average loss: 0.3549\n",
      "Iteration: 3250; Percent complete: 54.2%; Average loss: 0.2696\n",
      "Iteration: 3500; Percent complete: 58.3%; Average loss: 0.2100\n",
      "Iteration: 3750; Percent complete: 62.5%; Average loss: 0.1636\n",
      "Iteration: 4000; Percent complete: 66.7%; Average loss: 0.1319\n",
      "content/cb_model/Chat/2-4_512\n",
      "Iteration: 4250; Percent complete: 70.8%; Average loss: 0.1128\n",
      "Iteration: 4500; Percent complete: 75.0%; Average loss: 0.0901\n",
      "Iteration: 4750; Percent complete: 79.2%; Average loss: 0.0793\n",
      "Iteration: 5000; Percent complete: 83.3%; Average loss: 0.0676\n",
      "Iteration: 5250; Percent complete: 87.5%; Average loss: 0.0582\n",
      "Iteration: 5500; Percent complete: 91.7%; Average loss: 0.0585\n",
      "Iteration: 5750; Percent complete: 95.8%; Average loss: 0.0530\n",
      "Iteration: 6000; Percent complete: 100.0%; Average loss: 0.0490\n",
      "content/cb_model/Chat/2-4_512\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'content/'\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 6000\n",
    "print_every = 250\n",
    "save_every = 2000\n",
    "loadFilename = None\n",
    "corpus_name=\"Chat\"\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "print(\"Starting Training!\")\n",
    "lossvalues = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9501735400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(lossvalues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.3 Bleu score Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2777777777777778 0.040422604172722164\n",
      "Total Bleu Score for 1 grams on testing pairs:  0.30077562775304495\n",
      "Total Bleu Score for 2 grams on testing pairs:  0.1783754233334607\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "############################################################################\n",
    "# Difference between greedy search and beam search is here\n",
    "\n",
    "# greedy search\n",
    "# searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# beam search\n",
    "searcher = BeamSearchDecoder(encoder, decoder, voc, 10)\n",
    "############################################################################\n",
    "gram1_bleu_score = []\n",
    "gram2_bleu_score = []\n",
    "\n",
    "for i in range(0,len(testpairs),1):\n",
    "#     print('im here')\n",
    "    input_sentence = testpairs[i][0]\n",
    "\n",
    "    reference = testpairs[i][1:]\n",
    "    templist = []\n",
    "    for k in range(len(reference)):\n",
    "#         print('im here2')\n",
    "        if(reference[k]!=''):\n",
    "#             print('im here3')\n",
    "            temp = reference[k].split(' ')\n",
    "            templist.append(temp)\n",
    "\n",
    "\n",
    "        input_sentence = normalizeString(input_sentence)\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "        output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "        chencherry = SmoothingFunction()\n",
    "        score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\n",
    "        score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \n",
    "#         print(score1)\n",
    "#         print(score2)\n",
    "        gram1_bleu_score.append(score1)\n",
    "        gram2_bleu_score.append(score2)\n",
    "        if i%1000 == 0:\n",
    "            print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\n",
    "print(\"Total Bleu Score for 1 grams on testing pairs: \", sum(gram1_bleu_score)/len(gram1_bleu_score))  \n",
    "print(\"Total Bleu Score for 2 grams on testing pairs: \", sum(gram2_bleu_score)/len(gram2_bleu_score))  \n",
    "# print(gram1_bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.4. Chatting with BOT / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  restuarant\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: there is a lot . what is your price range ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Encountered unknown word.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  not expensive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: is there a certain area you re looking for ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  downtown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: is there a certain part of town you re looking for ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  at the center\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i have a few . what would you like to know ?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-72fb9220f3db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msearcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeamSearchDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-ec18c2cf8348>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "searcher = BeamSearchDecoder(encoder, decoder, voc, 10)\n",
    "evaluateInput(encoder, decoder, searcher, voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What i learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I learnt the two different search algorithms adopted in the decoder namely Greedy and Beam search. Greedy search defines word with maximum provavility at every step. This method does not ensure optimal solution. On the other hand Beam search adds k candidate to the greedy search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
