{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulation-pulse",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-magic",
   "metadata": {},
   "source": [
    "1. Create VSCode projects for each of these three networks. Be sure to properly define your Python classes, with one class per file and a main module that sets up your\n",
    "   objects, runs the training process, and saves the necessary data.\n",
    " \n",
    "The screenshot proves which show that i got my vscode working are at the end of the respective section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-monaco",
   "metadata": {},
   "source": [
    "2. Note that the AlexNet implementation here does not have the local response normalization feature described in the paper. Take a look at the\n",
    "   [PyTorch implementation of LRN](https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html) and incorporate it into your AlexNet implementation as\n",
    "   it is described in the paper. Compare your test set results with and without LRN.\n",
    "\n",
    "See the implementation under AlexNet section.\n",
    "\n",
    "* AlexNet Sequential: Train acc = 86.49%, Val acc = 76.64%, Test acc = 77.21%, Epoch time: 140s\n",
    "* AlexNet Sequential with LRN: Train acc = 87.21%, Val acc = 79.69%, Test acc = 79.21%, Epoch time: 170s\n",
    "* AlexNet nn.Module: Train acc = 87.29%, Val acc = 80.19% , Test acc = 80.86%, Epoch time: 159s\n",
    "* AlexNet nn.Module with LRN: Train acc = 85.21%, Val acc = 77.78% , Test acc = 77.99%, Epoch time: 143s\n",
    "\n",
    "When comparing the results of AlexNet Sequential model and those of AlexNet Sequential with LRN model, AlexNet Sequential with LRN model outperforms AlexNet Sequential without LRN model by around 2%, however it takes longer to complete training. The results also align to what is described in the paper. Moreover, the plots of AlexNet with LRN implemented are also smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-loading",
   "metadata": {},
   "source": [
    "3. Note that the backbone of the GoogLeNet implemented thus far does not correspond exactly to the description. Modify the architecture to\n",
    "   1. Use the same backbone (input image size, convolutions, etc.) before the first Inception module\n",
    "   2. Add the two side classifiers\n",
    "\n",
    "See the implementation under GoogLeNet section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-isolation",
   "metadata": {},
   "source": [
    "4. Compare your GoogLeNet and AlexNet implementations on CIFAR-10. Comment on the number of parameters, speed of training, and accuracy of the two models on this dataset when\n",
    "   trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-blackjack",
   "metadata": {},
   "source": [
    "* AlexNet Sequential with LRN:\n",
    "<br> &emsp; &emsp; &emsp;Train acc = 87.21%, \n",
    "<br> &emsp; &emsp; &emsp;Val acc = 79.69%, \n",
    "<br> &emsp; &emsp; &emsp;Test acc = 79.21%\n",
    "<br> &emsp; &emsp; &emsp;Epoch Time = 2m 50s,    \n",
    "&emsp; &emsp; &emsp; Number of trainable parameters = 58,322,314\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-defense",
   "metadata": {},
   "source": [
    "Note: there are 4 different versions of AlexNet model experimented in this lab, however the best performing AlexNet model version was selected for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-mission",
   "metadata": {},
   "source": [
    "* GoogLeNet:\n",
    "<br> &emsp; &emsp; Train acc = 91.58 %,\n",
    "<br> &emsp; &emsp; Val acc = 96.62%, \n",
    "<br> &emsp; &emsp; Test acc = 86.77%,\n",
    "<br> &emsp; &emsp; Epoch Time = 22m 43s,   \n",
    "&emsp; &emsp; Number of trainable parameters = 10,635,134    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-suicide",
   "metadata": {},
   "source": [
    "As shown abovem GoogLeNet could achieve a considerably higher accuracies while having the number of trainable parameters lower. However, GoogLeNet seems to require a lot more training time and takes more time to converge when compared to AlexNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-scientist",
   "metadata": {},
   "source": [
    "5. Experiment with the pretrained GoogLeNet from the torchvision repository. Does it give better results on CIFAR-10 similar to what we found with AlexNet last week? Comment\n",
    "   on what we can glean from the results about the capacity and generalization ability of these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-monthly",
   "metadata": {},
   "source": [
    "* Pretrained AlexNet: \n",
    "<br> &emsp; &emsp; &emsp; Train acc = 97.63%,\n",
    "<br> &emsp; &emsp; &emsp; Val acc = 89.22%, \n",
    "<br> &emsp; &emsp; &emsp; Test acc = 88.18%,\n",
    "<br> &emsp; &emsp; &emsp; Epoch Time = 2m 1s,   \n",
    "&emsp; &emsp; &emsp; Number of trainable parameters = 44,428,106\n",
    "    \n",
    "* Pretrained GoogLeNet: \n",
    "<br> &emsp; &emsp; &emsp; Train acc = 97.98%,\n",
    "<br> &emsp; &emsp; &emsp; Val acc = 99.40%, \n",
    "<br> &emsp; &emsp; &emsp; Test acc = 93.60%,\n",
    "<br> &emsp; &emsp; &emsp; Epoch Time = 21m 31s,   \n",
    "&emsp; &emsp; &emsp; Number of trainable parameters = 11,990,138\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-paradise",
   "metadata": {},
   "source": [
    "The pretrained version of both models perform better than that of the from-scratch version. Both versions of GoogLeNet achieve higher accuracies on Cifar-10 while having less the number of trainable parameters. However, they seem to require a lot more training time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
